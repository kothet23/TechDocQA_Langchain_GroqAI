{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74940e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain-community yt-dlp\n",
    "!pip install --upgrade yt-dlp langchain-community\n",
    "!pip install langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1a61aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver crescent in the night,\n",
      "The moon glows with gentle light.\n",
      "Her phases mark the passage of time,\n",
      "From new to full, a constant rhyme.\n",
      "\n",
      "With gentle beams, she illuminates,\n",
      "The darkness, and our soul creates,\n",
      "A sense of peace, a sense of rest,\n",
      "Under the moon's soft, lunar nest.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=[\"Write a poem about {word}, 100 words maximum\"])\n",
    "chain = prompt | llm \n",
    "response = chain.invoke({\"word\": \"moon\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unstructured beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a485ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_sub_urls(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    all_links = set()\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        full_url = urljoin(base_url, href)\n",
    "\n",
    "        # Optional: filter out non-HTTP(S) and non-visible links like mailto: or JavaScript\n",
    "        if full_url.startswith(\"http\"):\n",
    "            all_links.add(full_url)\n",
    "\n",
    "    return all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92be57b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://docs.python.org/3/tutorial/index.html\"\n",
    "len(get_sub_urls(base_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0554849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.tensorflow.org/tutorials\"\n",
    "len(get_sub_urls(base_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbe02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse, unquote\n",
    "\n",
    "def get_sub_urls_with_metadata(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    results = set()\n",
    "    cleaned_results = []\n",
    "\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        full_url = urljoin(base_url, href)\n",
    "\n",
    "        if full_url.startswith(\"http\") and full_url not in results:\n",
    "            results.add(full_url)\n",
    "\n",
    "            # Extract anchor text\n",
    "            anchor_text = a_tag.get_text(strip=True)\n",
    "\n",
    "            # Extract last part of path or fragment\n",
    "            parsed_url = urlparse(full_url)\n",
    "            last_part = unquote(parsed_url.fragment or parsed_url.path.rstrip(\"/\").split(\"/\")[-1])\n",
    "\n",
    "            # Combine anchor text + last part of URL for better metadata\n",
    "            full_text = anchor_text\n",
    "            if last_part and last_part.lower() not in anchor_text.lower():\n",
    "                full_text += f\" ({last_part})\"\n",
    "\n",
    "            cleaned_results.append({\n",
    "                \"url\": full_url,\n",
    "                \"text\": full_text\n",
    "            })\n",
    "\n",
    "    return cleaned_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30262927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://docs.python.org/3/library/index.html#library-index',\n",
       "  'text': 'The Python Standard Library (library-index)'},\n",
       " {'url': 'https://docs.python.org/3/reference/index.html#reference-index',\n",
       "  'text': 'The Python Language Reference (reference-index)'},\n",
       " {'url': 'https://docs.python.org/3/extending/index.html#extending-index',\n",
       "  'text': 'Extending and Embedding the Python Interpreter (extending-index)'},\n",
       " {'url': 'https://docs.python.org/3/c-api/index.html#c-api-index',\n",
       "  'text': 'Python/C API Reference Manual (c-api-index)'},\n",
       " {'url': 'https://docs.python.org/3/glossary.html#glossary',\n",
       "  'text': 'Glossary'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://docs.python.org/3/tutorial/index.html\"\n",
    "get_sub_urls_with_metadata(base_url)[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50cefa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://js.tensorflow.org/api/latest/',\n",
       "  'text': 'TensorFlow.js (latest)'},\n",
       " {'url': 'https://www.tensorflow.org/lite/api_docs',\n",
       "  'text': 'TensorFlow Lite (api_docs)'},\n",
       " {'url': 'https://www.tensorflow.org/tfx/api_docs', 'text': 'TFX (api_docs)'},\n",
       " {'url': 'https://www.tensorflow.org/resources/models-datasets',\n",
       "  'text': 'Ecosystem (models-datasets)'},\n",
       " {'url': 'https://www.tensorflow.org/js',\n",
       "  'text': 'TensorFlow.jsDevelop web ML applications in JavaScript'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"https://www.tensorflow.org/tutorials\"\n",
    "sublinks_tf = get_sub_urls_with_metadata(base_url)\n",
    "sublinks_tf[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f6b8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eiphyusinn/Desktop/NLP-Projects/OpenAI_NLP/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow Datasets (overview): https://www.tensorflow.org/datasets/overview\n",
      "Object detection with TF Hub (tf2_object_detection): https://www.tensorflow.org/hub/tutorials/tf2_object_detection\n",
      "Stack Overflow (tensorflow): https://stackoverflow.com/questions/tagged/tensorflow\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "link_texts = [item[\"text\"] for item in sublinks_tf]\n",
    "link_embeddings = model.encode(link_texts, convert_to_tensor=True)\n",
    "query = \"How do I detect objects in TensorFlow?\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, link_embeddings)[0]\n",
    "\n",
    "top_indices = cos_scores.topk(k=3).indices\n",
    "\n",
    "for idx in top_indices:\n",
    "    print(f\"{sublinks_tf[idx]['text']}: {sublinks_tf[idx]['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af1ca4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.tensorflow.org/datasets/overview', 'title': 'TensorFlow Datasets', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTensorFlow Datasets\\n\\n\\n\\n\\n\\n\\n\\n      \\n      Skip to main content\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Install\\n  \\n    \\n\\n\\n\\n    Learn\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      Introduction\\n                    \\n\\n                      New to TensorFlow?\\n                    \\n\\n\\n\\n\\n\\n                      Tutorials\\n                    \\n\\n                      Learn how to use TensorFlow with end-to-end examples\\n                    \\n\\n\\n\\n\\n\\n                      Guide\\n                    \\n\\n                      Learn framework concepts and components\\n                    \\n\\n\\n\\n\\n\\n                      Learn ML\\n                    \\n\\n                      Educational resources to master your path with TensorFlow\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    API\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      TensorFlow (v2.16.1)\\n                    \\n\\n\\n\\n\\n\\n                      Versions‚Ä¶\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                      TensorFlow.js\\n                    \\n\\n\\n\\n\\n\\n                      TensorFlow Lite\\n                    \\n\\n\\n\\n\\n\\n                      TFX\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Resources\\n  \\n    \\n\\n\\n\\n\\n\\nLIBRARIES\\n\\n\\n\\n                      TensorFlow.js\\n                    \\n\\n                      Develop web ML applications in JavaScript\\n                    \\n\\n\\n\\n\\n\\n                      TensorFlow Lite\\n                    \\n\\n                      Deploy ML on mobile, microcontrollers and other edge devices\\n                    \\n\\n\\n\\n\\n\\n                      TFX\\n                    \\n\\n                      Build production ML pipelines\\n                    \\n\\n\\n\\n\\n\\n                      All libraries\\n                    \\n\\n                      Create advanced models and extend TensorFlow\\n                    \\n\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\n\\n                      Models & datasets\\n                    \\n\\n                      Pre-trained models and datasets built by Google and the community\\n                    \\n\\n\\n\\n\\n\\n                      Tools\\n                    \\n\\n                      Tools to support and accelerate TensorFlow workflows\\n                    \\n\\n\\n\\n\\n\\n                      Responsible AI\\n                    \\n\\n                      Resources for every stage of the ML workflow\\n                    \\n\\n\\n\\n\\n\\n                      Recommendation systems\\n                    \\n\\n                      Build recommendation systems with open source tools\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Community\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      Groups\\n                    \\n\\n                      User groups, interest groups and mailing lists\\n                    \\n\\n\\n\\n\\n\\n                      Contribute\\n                    \\n\\n                      Guide for contributing to code and documentation\\n                    \\n\\n\\n\\n\\n\\n                      Blog\\n                    \\n\\n                      Stay up to date with all things TensorFlow\\n                    \\n\\n\\n\\n\\n\\n                      Forum\\n                    \\n\\n                      Discussion platform for the TensorFlow community\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Why TensorFlow\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      About\\n                    \\n\\n\\n\\n\\n\\n                      Case studies\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\nEspa√±ol ‚Äì Am√©rica Latina\\n\\n\\nFran√ßais\\n\\n\\nIndonesia\\n\\n\\nItaliano\\n\\n\\nPolski\\n\\n\\nPortugu√™s ‚Äì Brasil\\n\\n\\nTi√™ÃÅng Vi√™Ã£t\\n\\n\\nT√ºrk√ße\\n\\n\\n–†—É—Å—Å–∫–∏–π\\n\\n\\n◊¢◊ë◊®◊ô◊™\\n\\n\\nÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©\\n\\n\\nŸÅÿßÿ±ÿ≥€å\\n\\n\\n‡§π‡§ø‡§Ç‡§¶‡•Ä\\n\\n\\n‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ\\n\\n\\n‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\\n\\n\\n‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì\\n\\n\\nÊó•Êú¨Ë™û\\n\\n\\nÌïúÍµ≠Ïñ¥\\n\\n\\n\\n\\n  GitHub\\n\\n\\nSign in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        Datasets\\n      \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Overview\\n  \\n    \\n\\n\\n\\n    Catalog\\n  \\n    \\n\\n\\n\\n    Community Catalog\\n  \\n    \\n\\n\\n\\n    Guide\\n  \\n    \\n\\n\\n\\n    API\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Install\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Learn\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      API\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Resources\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Overview\\n   \\n\\n\\n\\n\\n\\n      Catalog\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Community Catalog\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Guide\\n   \\n\\n\\n\\n\\n\\n\\n\\n      API\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Community\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Why TensorFlow\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      GitHub\\n   \\n\\n\\n\\n\\n\\n\\n\\nGet started\\n\\nIntroduction\\nEnd-to-end Keras example\\nDataset collections\\n\\nFeatures & performances\\n\\nTFDS CLI\\nSplits and slicing API\\nPerformance tips\\nDeterminism\\nFeature connectors\\nFeature decoding\\nVersioning\\nStore your dataset on GCS\\nTFDS for Jax and PyTorch\\n\\nAdd a dataset\\n\\nCreate your dataset\\nHuge datasets (Apache Beam)\\nFormat-specific builders\\nAdd a dataset collection\\nContribute to TFDS\\nCommon gotchas\\nExternal tfrecord with TFDS\\n\\n\\n\\n\\n\\n      Introduction\\n   \\n\\n\\n\\n\\n\\n      Tutorials\\n   \\n\\n\\n\\n\\n\\n      Guide\\n   \\n\\n\\n\\n\\n\\n      Learn ML\\n   \\n\\n\\n\\n\\n\\n\\n\\n      TensorFlow (v2.16.1)\\n   \\n\\n\\n\\n\\n\\n      Versions‚Ä¶\\n   \\n\\n\\n\\n\\n\\n      TensorFlow.js\\n   \\n\\n\\n\\n\\n\\n      TensorFlow Lite\\n   \\n\\n\\n\\n\\n\\n      TFX\\n   \\n\\n\\n\\n\\n\\n\\n\\n      LIBRARIES\\n   \\n\\n\\n\\n\\n\\n      TensorFlow.js\\n   \\n\\n\\n\\n\\n\\n      TensorFlow Lite\\n   \\n\\n\\n\\n\\n\\n      TFX\\n   \\n\\n\\n\\n\\n\\n      All libraries\\n   \\n\\n\\n\\n\\n\\n      RESOURCES\\n   \\n\\n\\n\\n\\n\\n      Models & datasets\\n   \\n\\n\\n\\n\\n\\n      Tools\\n   \\n\\n\\n\\n\\n\\n      Responsible AI\\n   \\n\\n\\n\\n\\n\\n      Recommendation systems\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Groups\\n   \\n\\n\\n\\n\\n\\n      Contribute\\n   \\n\\n\\n\\n\\n\\n      Blog\\n   \\n\\n\\n\\n\\n\\n      Forum\\n   \\n\\n\\n\\n\\n\\n\\n\\n      About\\n   \\n\\n\\n\\n\\n\\n      Case studies\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  TFDS now supports the Croissant \\uf8ffü•ê format! Read the\\n  documentation\\n  to know more.\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        TensorFlow\\n      \\n  \\n\\n\\n\\n\\n    \\n        Resources\\n      \\n  \\n\\n\\n\\n\\n    \\n        Datasets\\n      \\n  \\n\\n\\n\\n\\n    \\n        Guide\\n      \\n  \\n\\n\\n\\n\\n\\n\\n      TensorFlow Datasets\\n      \\n\\n\\n      \\n      Stay organized with collections\\n    \\n\\n      \\n      Save and categorize content based on your preferences.\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTFDS provides a collection of ready-to-use datasets for use with TensorFlow, Jax, and other Machine Learning frameworks.\\nIt handles downloading and preparing the data deterministically and constructing a tf.data.Dataset (or np.array).\\nNote: Do not confuse TFDS (this library) with tf.data (TensorFlow API to build efficient data pipelines). TFDS is a high level wrapper around tf.data. If you\\'re not familiar with this API, we encourage you to read the official tf.data guide first.\\n\\n\\nView on TensorFlow.org\\n\\n\\nRun in Google Colab\\n\\n\\nView source on GitHub\\n\\n\\nDownload notebook\\n\\n\\nInstallation\\nTFDS exists in two packages:\\n\\npip install tensorflow-datasets: The stable version, released every few months.\\npip install tfds-nightly: Released every day, contains the last versions of the datasets.\\n\\nThis colab uses tfds-nightly:\\npip install -q tfds-nightly tensorflow matplotlib\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport tensorflow as tf\\n\\nimport tensorflow_datasets as tfds\\n\\n\\n2024-12-14 12:41:53.251913: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\\nE0000 00:00:1734180113.275388  782567 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\\nE0000 00:00:1734180113.282524  782567 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\\n\\nFind available datasets\\nAll dataset builders are subclass of tfds.core.DatasetBuilder. To get the list of available builders, use tfds.list_builders() or look at our catalog.\\ntfds.list_builders()\\n\\n\\n[\\'abstract_reasoning\\',\\n \\'accentdb\\',\\n \\'aeslc\\',\\n \\'aflw2k3d\\',\\n \\'ag_news_subset\\',\\n \\'ai2_arc\\',\\n \\'ai2_arc_with_ir\\',\\n \\'amazon_us_reviews\\',\\n \\'anli\\',\\n \\'answer_equivalence\\',\\n \\'arc\\',\\n \\'asqa\\',\\n \\'asset\\',\\n \\'assin2\\',\\n \\'asu_table_top_converted_externally_to_rlds\\',\\n \\'austin_buds_dataset_converted_externally_to_rlds\\',\\n \\'austin_sailor_dataset_converted_externally_to_rlds\\',\\n \\'austin_sirius_dataset_converted_externally_to_rlds\\',\\n \\'bair_robot_pushing_small\\',\\n \\'bc_z\\',\\n \\'bccd\\',\\n \\'beans\\',\\n \\'bee_dataset\\',\\n \\'beir\\',\\n \\'berkeley_autolab_ur5\\',\\n \\'berkeley_cable_routing\\',\\n \\'berkeley_fanuc_manipulation\\',\\n \\'berkeley_gnm_cory_hall\\',\\n \\'berkeley_gnm_recon\\',\\n \\'berkeley_gnm_sac_son\\',\\n \\'berkeley_mvp_converted_externally_to_rlds\\',\\n \\'berkeley_rpt_converted_externally_to_rlds\\',\\n \\'big_patent\\',\\n \\'bigearthnet\\',\\n \\'billsum\\',\\n \\'binarized_mnist\\',\\n \\'binary_alpha_digits\\',\\n \\'ble_wind_field\\',\\n \\'blimp\\',\\n \\'booksum\\',\\n \\'bool_q\\',\\n \\'bot_adversarial_dialogue\\',\\n \\'bridge\\',\\n \\'bucc\\',\\n \\'c4\\',\\n \\'c4_wsrs\\',\\n \\'caltech101\\',\\n \\'caltech_birds2010\\',\\n \\'caltech_birds2011\\',\\n \\'cardiotox\\',\\n \\'cars196\\',\\n \\'cassava\\',\\n \\'cats_vs_dogs\\',\\n \\'celeb_a\\',\\n \\'celeb_a_hq\\',\\n \\'cfq\\',\\n \\'cherry_blossoms\\',\\n \\'chexpert\\',\\n \\'cifar10\\',\\n \\'cifar100\\',\\n \\'cifar100_n\\',\\n \\'cifar10_1\\',\\n \\'cifar10_corrupted\\',\\n \\'cifar10_h\\',\\n \\'cifar10_n\\',\\n \\'citrus_leaves\\',\\n \\'cityscapes\\',\\n \\'civil_comments\\',\\n \\'clevr\\',\\n \\'clic\\',\\n \\'clinc_oos\\',\\n \\'cmaterdb\\',\\n \\'cmu_franka_exploration_dataset_converted_externally_to_rlds\\',\\n \\'cmu_play_fusion\\',\\n \\'cmu_stretch\\',\\n \\'cnn_dailymail\\',\\n \\'coco\\',\\n \\'coco_captions\\',\\n \\'coil100\\',\\n \\'colorectal_histology\\',\\n \\'colorectal_histology_large\\',\\n \\'columbia_cairlab_pusht_real\\',\\n \\'common_voice\\',\\n \\'conll2002\\',\\n \\'conll2003\\',\\n \\'controlled_noisy_web_labels\\',\\n \\'coqa\\',\\n \\'corr2cause\\',\\n \\'cos_e\\',\\n \\'cosmos_qa\\',\\n \\'covid19\\',\\n \\'covid19sum\\',\\n \\'crema_d\\',\\n \\'criteo\\',\\n \\'cs_restaurants\\',\\n \\'curated_breast_imaging_ddsm\\',\\n \\'cycle_gan\\',\\n \\'d4rl_adroit_door\\',\\n \\'d4rl_adroit_hammer\\',\\n \\'d4rl_adroit_pen\\',\\n \\'d4rl_adroit_relocate\\',\\n \\'d4rl_antmaze\\',\\n \\'d4rl_mujoco_ant\\',\\n \\'d4rl_mujoco_halfcheetah\\',\\n \\'d4rl_mujoco_hopper\\',\\n \\'d4rl_mujoco_walker2d\\',\\n \\'dart\\',\\n \\'databricks_dolly\\',\\n \\'davis\\',\\n \\'deep1b\\',\\n \\'deep_weeds\\',\\n \\'definite_pronoun_resolution\\',\\n \\'dementiabank\\',\\n \\'diabetic_retinopathy_detection\\',\\n \\'diamonds\\',\\n \\'div2k\\',\\n \\'dlr_edan_shared_control_converted_externally_to_rlds\\',\\n \\'dlr_sara_grid_clamp_converted_externally_to_rlds\\',\\n \\'dlr_sara_pour_converted_externally_to_rlds\\',\\n \\'dmlab\\',\\n \\'doc_nli\\',\\n \\'dolphin_number_word\\',\\n \\'domainnet\\',\\n \\'downsampled_imagenet\\',\\n \\'drop\\',\\n \\'dsprites\\',\\n \\'dtd\\',\\n \\'duke_ultrasound\\',\\n \\'e2e_cleaned\\',\\n \\'efron_morris75\\',\\n \\'emnist\\',\\n \\'eraser_multi_rc\\',\\n \\'esnli\\',\\n \\'eth_agent_affordances\\',\\n \\'eurosat\\',\\n \\'fashion_mnist\\',\\n \\'flic\\',\\n \\'flores\\',\\n \\'food101\\',\\n \\'forest_fires\\',\\n \\'fractal20220817_data\\',\\n \\'fuss\\',\\n \\'gap\\',\\n \\'geirhos_conflict_stimuli\\',\\n \\'gem\\',\\n \\'genomics_ood\\',\\n \\'german_credit_numeric\\',\\n \\'gigaword\\',\\n \\'glove100_angular\\',\\n \\'glue\\',\\n \\'goemotions\\',\\n \\'gov_report\\',\\n \\'gpt3\\',\\n \\'gref\\',\\n \\'groove\\',\\n \\'grounded_scan\\',\\n \\'gsm8k\\',\\n \\'gtzan\\',\\n \\'gtzan_music_speech\\',\\n \\'hellaswag\\',\\n \\'higgs\\',\\n \\'hillstrom\\',\\n \\'horses_or_humans\\',\\n \\'howell\\',\\n \\'i_naturalist2017\\',\\n \\'i_naturalist2018\\',\\n \\'i_naturalist2021\\',\\n \\'iamlab_cmu_pickup_insert_converted_externally_to_rlds\\',\\n \\'imagenet2012\\',\\n \\'imagenet2012_corrupted\\',\\n \\'imagenet2012_fewshot\\',\\n \\'imagenet2012_multilabel\\',\\n \\'imagenet2012_real\\',\\n \\'imagenet2012_subset\\',\\n \\'imagenet_a\\',\\n \\'imagenet_lt\\',\\n \\'imagenet_pi\\',\\n \\'imagenet_r\\',\\n \\'imagenet_resized\\',\\n \\'imagenet_sketch\\',\\n \\'imagenet_v2\\',\\n \\'imagenette\\',\\n \\'imagewang\\',\\n \\'imdb_reviews\\',\\n \\'imperialcollege_sawyer_wrist_cam\\',\\n \\'irc_disentanglement\\',\\n \\'iris\\',\\n \\'istella\\',\\n \\'jaco_play\\',\\n \\'kaist_nonprehensile_converted_externally_to_rlds\\',\\n \\'kddcup99\\',\\n \\'kitti\\',\\n \\'kmnist\\',\\n \\'kuka\\',\\n \\'laion400m\\',\\n \\'lambada\\',\\n \\'lfw\\',\\n \\'librispeech\\',\\n \\'librispeech_lm\\',\\n \\'libritts\\',\\n \\'ljspeech\\',\\n \\'lm1b\\',\\n \\'locomotion\\',\\n \\'lost_and_found\\',\\n \\'lsun\\',\\n \\'lvis\\',\\n \\'malaria\\',\\n \\'maniskill_dataset_converted_externally_to_rlds\\',\\n \\'math_dataset\\',\\n \\'math_qa\\',\\n \\'mctaco\\',\\n \\'media_sum\\',\\n \\'mlqa\\',\\n \\'mnist\\',\\n \\'mnist_corrupted\\',\\n \\'movie_lens\\',\\n \\'movie_rationales\\',\\n \\'movielens\\',\\n \\'moving_mnist\\',\\n \\'mrqa\\',\\n \\'mslr_web\\',\\n \\'mt_opt\\',\\n \\'mtnt\\',\\n \\'multi_news\\',\\n \\'multi_nli\\',\\n \\'multi_nli_mismatch\\',\\n \\'natural_instructions\\',\\n \\'natural_questions\\',\\n \\'natural_questions_open\\',\\n \\'newsroom\\',\\n \\'nsynth\\',\\n \\'nyu_depth_v2\\',\\n \\'nyu_door_opening_surprising_effectiveness\\',\\n \\'nyu_franka_play_dataset_converted_externally_to_rlds\\',\\n \\'nyu_rot_dataset_converted_externally_to_rlds\\',\\n \\'ogbg_molpcba\\',\\n \\'omniglot\\',\\n \\'open_images_challenge2019_detection\\',\\n \\'open_images_v4\\',\\n \\'openbookqa\\',\\n \\'opinion_abstracts\\',\\n \\'opinosis\\',\\n \\'opus\\',\\n \\'oxford_flowers102\\',\\n \\'oxford_iiit_pet\\',\\n \\'para_crawl\\',\\n \\'pass\\',\\n \\'patch_camelyon\\',\\n \\'paws_wiki\\',\\n \\'paws_x_wiki\\',\\n \\'penguins\\',\\n \\'pet_finder\\',\\n \\'pg19\\',\\n \\'piqa\\',\\n \\'places365_small\\',\\n \\'placesfull\\',\\n \\'plant_leaves\\',\\n \\'plant_village\\',\\n \\'plantae_k\\',\\n \\'protein_net\\',\\n \\'q_re_cc\\',\\n \\'qa4mre\\',\\n \\'qasc\\',\\n \\'quac\\',\\n \\'quality\\',\\n \\'quickdraw_bitmap\\',\\n \\'race\\',\\n \\'radon\\',\\n \\'real_toxicity_prompts\\',\\n \\'reddit\\',\\n \\'reddit_disentanglement\\',\\n \\'reddit_tifu\\',\\n \\'ref_coco\\',\\n \\'resisc45\\',\\n \\'rlu_atari\\',\\n \\'rlu_atari_checkpoints\\',\\n \\'rlu_atari_checkpoints_ordered\\',\\n \\'rlu_control_suite\\',\\n \\'rlu_dmlab_explore_object_rewards_few\\',\\n \\'rlu_dmlab_explore_object_rewards_many\\',\\n \\'rlu_dmlab_rooms_select_nonmatching_object\\',\\n \\'rlu_dmlab_rooms_watermaze\\',\\n \\'rlu_dmlab_seekavoid_arena01\\',\\n \\'rlu_locomotion\\',\\n \\'rlu_rwrl\\',\\n \\'robomimic_mg\\',\\n \\'robomimic_mh\\',\\n \\'robomimic_ph\\',\\n \\'robonet\\',\\n \\'robosuite_panda_pick_place_can\\',\\n \\'roboturk\\',\\n \\'rock_paper_scissors\\',\\n \\'rock_you\\',\\n \\'s3o4d\\',\\n \\'salient_span_wikipedia\\',\\n \\'samsum\\',\\n \\'savee\\',\\n \\'scan\\',\\n \\'scene_parse150\\',\\n \\'schema_guided_dialogue\\',\\n \\'sci_tail\\',\\n \\'scicite\\',\\n \\'scientific_papers\\',\\n \\'scrolls\\',\\n \\'segment_anything\\',\\n \\'sentiment140\\',\\n \\'shapes3d\\',\\n \\'sift1m\\',\\n \\'simpte\\',\\n \\'siscore\\',\\n \\'smallnorb\\',\\n \\'smartwatch_gestures\\',\\n \\'snli\\',\\n \\'so2sat\\',\\n \\'speech_commands\\',\\n \\'spoken_digit\\',\\n \\'squad\\',\\n \\'squad_question_generation\\',\\n \\'stanford_dogs\\',\\n \\'stanford_hydra_dataset_converted_externally_to_rlds\\',\\n \\'stanford_kuka_multimodal_dataset_converted_externally_to_rlds\\',\\n \\'stanford_mask_vit_converted_externally_to_rlds\\',\\n \\'stanford_online_products\\',\\n \\'stanford_robocook_converted_externally_to_rlds\\',\\n \\'star_cfq\\',\\n \\'starcraft_video\\',\\n \\'stl10\\',\\n \\'story_cloze\\',\\n \\'summscreen\\',\\n \\'sun397\\',\\n \\'super_glue\\',\\n \\'svhn_cropped\\',\\n \\'symmetric_solids\\',\\n \\'taco_play\\',\\n \\'tao\\',\\n \\'tatoeba\\',\\n \\'ted_hrlr_translate\\',\\n \\'ted_multi_translate\\',\\n \\'tedlium\\',\\n \\'tf_flowers\\',\\n \\'the300w_lp\\',\\n \\'tiny_shakespeare\\',\\n \\'titanic\\',\\n \\'tokyo_u_lsmo_converted_externally_to_rlds\\',\\n \\'toto\\',\\n \\'trec\\',\\n \\'trivia_qa\\',\\n \\'tydi_qa\\',\\n \\'uc_merced\\',\\n \\'ucf101\\',\\n \\'ucsd_kitchen_dataset_converted_externally_to_rlds\\',\\n \\'ucsd_pick_and_place_dataset_converted_externally_to_rlds\\',\\n \\'uiuc_d3field\\',\\n \\'unified_qa\\',\\n \\'universal_dependencies\\',\\n \\'unnatural_instructions\\',\\n \\'usc_cloth_sim_converted_externally_to_rlds\\',\\n \\'user_libri_audio\\',\\n \\'user_libri_text\\',\\n \\'utaustin_mutex\\',\\n \\'utokyo_pr2_opening_fridge_converted_externally_to_rlds\\',\\n \\'utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds\\',\\n \\'utokyo_saytap_converted_externally_to_rlds\\',\\n \\'utokyo_xarm_bimanual_converted_externally_to_rlds\\',\\n \\'utokyo_xarm_pick_and_place_converted_externally_to_rlds\\',\\n \\'vctk\\',\\n \\'viola\\',\\n \\'visual_domain_decathlon\\',\\n \\'voc\\',\\n \\'voxceleb\\',\\n \\'voxforge\\',\\n \\'waymo_open_dataset\\',\\n \\'web_graph\\',\\n \\'web_nlg\\',\\n \\'web_questions\\',\\n \\'webvid\\',\\n \\'wider_face\\',\\n \\'wiki40b\\',\\n \\'wiki_auto\\',\\n \\'wiki_bio\\',\\n \\'wiki_dialog\\',\\n \\'wiki_table_questions\\',\\n \\'wiki_table_text\\',\\n \\'wikiann\\',\\n \\'wikihow\\',\\n \\'wikipedia\\',\\n \\'wikipedia_toxicity_subtypes\\',\\n \\'wine_quality\\',\\n \\'winogrande\\',\\n \\'wit\\',\\n \\'wit_kaggle\\',\\n \\'wmt13_translate\\',\\n \\'wmt14_translate\\',\\n \\'wmt15_translate\\',\\n \\'wmt16_translate\\',\\n \\'wmt17_translate\\',\\n \\'wmt18_translate\\',\\n \\'wmt19_translate\\',\\n \\'wmt_t2t_translate\\',\\n \\'wmt_translate\\',\\n \\'wordnet\\',\\n \\'wsc273\\',\\n \\'xnli\\',\\n \\'xquad\\',\\n \\'xsum\\',\\n \\'xtreme_pawsx\\',\\n \\'xtreme_pos\\',\\n \\'xtreme_s\\',\\n \\'xtreme_xnli\\',\\n \\'yahoo_ltrc\\',\\n \\'yelp_polarity_reviews\\',\\n \\'yes_no\\',\\n \\'youtube_vis\\',\\n \\'huggingface:acronym_identification\\',\\n \\'huggingface:ade_corpus_v2\\',\\n \\'huggingface:adv_glue\\',\\n \\'huggingface:adversarial_qa\\',\\n \\'huggingface:aeslc\\',\\n \\'huggingface:afrikaans_ner_corpus\\',\\n \\'huggingface:ag_news\\',\\n \\'huggingface:ai2_arc\\',\\n \\'huggingface:air_dialogue\\',\\n \\'huggingface:ajgt_twitter_ar\\',\\n \\'huggingface:allegro_reviews\\',\\n \\'huggingface:allocine\\',\\n \\'huggingface:alt\\',\\n \\'huggingface:amazon_polarity\\',\\n \\'huggingface:amazon_reviews_multi\\',\\n \\'huggingface:amazon_us_reviews\\',\\n \\'huggingface:ambig_qa\\',\\n \\'huggingface:americas_nli\\',\\n \\'huggingface:ami\\',\\n \\'huggingface:amttl\\',\\n \\'huggingface:anli\\',\\n \\'huggingface:app_reviews\\',\\n \\'huggingface:aqua_rat\\',\\n \\'huggingface:aquamuse\\',\\n \\'huggingface:ar_cov19\\',\\n \\'huggingface:ar_res_reviews\\',\\n \\'huggingface:ar_sarcasm\\',\\n \\'huggingface:arabic_billion_words\\',\\n \\'huggingface:arabic_pos_dialect\\',\\n \\'huggingface:arabic_speech_corpus\\',\\n \\'huggingface:arcd\\',\\n \\'huggingface:arsentd_lev\\',\\n \\'huggingface:art\\',\\n \\'huggingface:arxiv_dataset\\',\\n \\'huggingface:ascent_kb\\',\\n \\'huggingface:aslg_pc12\\',\\n \\'huggingface:asnq\\',\\n \\'huggingface:asset\\',\\n \\'huggingface:assin\\',\\n \\'huggingface:assin2\\',\\n \\'huggingface:atomic\\',\\n \\'huggingface:autshumato\\',\\n \\'huggingface:babi_qa\\',\\n \\'huggingface:banking77\\',\\n \\'huggingface:bbaw_egyptian\\',\\n \\'huggingface:bbc_hindi_nli\\',\\n \\'huggingface:bc2gm_corpus\\',\\n \\'huggingface:beans\\',\\n \\'huggingface:best2009\\',\\n \\'huggingface:bianet\\',\\n \\'huggingface:bible_para\\',\\n \\'huggingface:big_patent\\',\\n \\'huggingface:bigbench\\',\\n \\'huggingface:billsum\\',\\n \\'huggingface:bing_coronavirus_query_set\\',\\n \\'huggingface:biomrc\\',\\n \\'huggingface:biosses\\',\\n \\'huggingface:biwi_kinect_head_pose\\',\\n \\'huggingface:blbooks\\',\\n \\'huggingface:blbooksgenre\\',\\n \\'huggingface:blended_skill_talk\\',\\n \\'huggingface:blimp\\',\\n \\'huggingface:blog_authorship_corpus\\',\\n \\'huggingface:bn_hate_speech\\',\\n \\'huggingface:bnl_newspapers\\',\\n \\'huggingface:bookcorpus\\',\\n \\'huggingface:bookcorpusopen\\',\\n \\'huggingface:boolq\\',\\n \\'huggingface:bprec\\',\\n \\'huggingface:break_data\\',\\n \\'huggingface:brwac\\',\\n \\'huggingface:bsd_ja_en\\',\\n \\'huggingface:bswac\\',\\n \\'huggingface:c3\\',\\n \\'huggingface:c4\\',\\n \\'huggingface:cail2018\\',\\n \\'huggingface:caner\\',\\n \\'huggingface:capes\\',\\n \\'huggingface:casino\\',\\n \\'huggingface:catalonia_independence\\',\\n \\'huggingface:cats_vs_dogs\\',\\n \\'huggingface:cawac\\',\\n \\'huggingface:cbt\\',\\n \\'huggingface:cc100\\',\\n \\'huggingface:cc_news\\',\\n \\'huggingface:ccaligned_multilingual\\',\\n \\'huggingface:cdsc\\',\\n \\'huggingface:cdt\\',\\n \\'huggingface:cedr\\',\\n \\'huggingface:cfq\\',\\n \\'huggingface:chr_en\\',\\n \\'huggingface:cifar10\\',\\n \\'huggingface:cifar100\\',\\n \\'huggingface:circa\\',\\n \\'huggingface:civil_comments\\',\\n \\'huggingface:clickbait_news_bg\\',\\n \\'huggingface:climate_fever\\',\\n \\'huggingface:clinc_oos\\',\\n \\'huggingface:clue\\',\\n \\'huggingface:cmrc2018\\',\\n \\'huggingface:cmu_hinglish_dog\\',\\n \\'huggingface:cnn_dailymail\\',\\n \\'huggingface:coached_conv_pref\\',\\n \\'huggingface:coarse_discourse\\',\\n \\'huggingface:codah\\',\\n \\'huggingface:code_search_net\\',\\n \\'huggingface:code_x_glue_cc_clone_detection_big_clone_bench\\',\\n \\'huggingface:code_x_glue_cc_clone_detection_poj104\\',\\n \\'huggingface:code_x_glue_cc_cloze_testing_all\\',\\n \\'huggingface:code_x_glue_cc_cloze_testing_maxmin\\',\\n \\'huggingface:code_x_glue_cc_code_completion_line\\',\\n \\'huggingface:code_x_glue_cc_code_completion_token\\',\\n \\'huggingface:code_x_glue_cc_code_refinement\\',\\n \\'huggingface:code_x_glue_cc_code_to_code_trans\\',\\n \\'huggingface:code_x_glue_cc_defect_detection\\',\\n \\'huggingface:code_x_glue_ct_code_to_text\\',\\n \\'huggingface:code_x_glue_tc_nl_code_search_adv\\',\\n \\'huggingface:code_x_glue_tc_text_to_code\\',\\n \\'huggingface:code_x_glue_tt_text_to_text\\',\\n \\'huggingface:com_qa\\',\\n \\'huggingface:common_gen\\',\\n \\'huggingface:common_language\\',\\n \\'huggingface:common_voice\\',\\n \\'huggingface:commonsense_qa\\',\\n \\'huggingface:competition_math\\',\\n \\'huggingface:compguesswhat\\',\\n \\'huggingface:conceptnet5\\',\\n \\'huggingface:conceptual_12m\\',\\n \\'huggingface:conceptual_captions\\',\\n \\'huggingface:conll2000\\',\\n \\'huggingface:conll2002\\',\\n \\'huggingface:conll2003\\',\\n \\'huggingface:conll2012_ontonotesv5\\',\\n \\'huggingface:conllpp\\',\\n \\'huggingface:consumer-finance-complaints\\',\\n \\'huggingface:conv_ai\\',\\n \\'huggingface:conv_ai_2\\',\\n \\'huggingface:conv_ai_3\\',\\n \\'huggingface:conv_questions\\',\\n \\'huggingface:coqa\\',\\n \\'huggingface:cord19\\',\\n \\'huggingface:cornell_movie_dialog\\',\\n \\'huggingface:cos_e\\',\\n \\'huggingface:cosmos_qa\\',\\n \\'huggingface:counter\\',\\n \\'huggingface:covid_qa_castorini\\',\\n \\'huggingface:covid_qa_deepset\\',\\n \\'huggingface:covid_qa_ucsd\\',\\n \\'huggingface:covid_tweets_japanese\\',\\n \\'huggingface:covost2\\',\\n \\'huggingface:cppe-5\\',\\n \\'huggingface:craigslist_bargains\\',\\n \\'huggingface:crawl_domain\\',\\n \\'huggingface:crd3\\',\\n \\'huggingface:crime_and_punish\\',\\n \\'huggingface:crows_pairs\\',\\n \\'huggingface:cryptonite\\',\\n \\'huggingface:cs_restaurants\\',\\n \\'huggingface:cuad\\',\\n \\'huggingface:curiosity_dialogs\\',\\n \\'huggingface:daily_dialog\\',\\n \\'huggingface:dane\\',\\n \\'huggingface:danish_political_comments\\',\\n \\'huggingface:dart\\',\\n \\'huggingface:datacommons_factcheck\\',\\n \\'huggingface:dbpedia_14\\',\\n \\'huggingface:dbrd\\',\\n \\'huggingface:deal_or_no_dialog\\',\\n \\'huggingface:definite_pronoun_resolution\\',\\n \\'huggingface:dengue_filipino\\',\\n \\'huggingface:dialog_re\\',\\n \\'huggingface:diplomacy_detection\\',\\n \\'huggingface:disaster_response_messages\\',\\n \\'huggingface:discofuse\\',\\n \\'huggingface:discovery\\',\\n \\'huggingface:disfl_qa\\',\\n \\'huggingface:doc2dial\\',\\n \\'huggingface:docred\\',\\n \\'huggingface:doqa\\',\\n \\'huggingface:dream\\',\\n \\'huggingface:drop\\',\\n \\'huggingface:duorc\\',\\n \\'huggingface:dutch_social\\',\\n \\'huggingface:dyk\\',\\n \\'huggingface:e2e_nlg\\',\\n \\'huggingface:e2e_nlg_cleaned\\',\\n \\'huggingface:ecb\\',\\n \\'huggingface:ecthr_cases\\',\\n \\'huggingface:eduge\\',\\n \\'huggingface:ehealth_kd\\',\\n \\'huggingface:eitb_parcc\\',\\n \\'huggingface:electricity_load_diagrams\\',\\n \\'huggingface:eli5\\',\\n \\'huggingface:eli5_category\\',\\n \\'huggingface:elkarhizketak\\',\\n \\'huggingface:emea\\',\\n \\'huggingface:emo\\',\\n \\'huggingface:emotion\\',\\n \\'huggingface:emotone_ar\\',\\n \\'huggingface:empathetic_dialogues\\',\\n \\'huggingface:enriched_web_nlg\\',\\n \\'huggingface:enwik8\\',\\n \\'huggingface:eraser_multi_rc\\',\\n \\'huggingface:esnli\\',\\n \\'huggingface:eth_py150_open\\',\\n \\'huggingface:ethos\\',\\n \\'huggingface:ett\\',\\n \\'huggingface:eu_regulatory_ir\\',\\n \\'huggingface:eurlex\\',\\n \\'huggingface:euronews\\',\\n \\'huggingface:europa_eac_tm\\',\\n \\'huggingface:europa_ecdc_tm\\',\\n \\'huggingface:europarl_bilingual\\',\\n \\'huggingface:event2Mind\\',\\n \\'huggingface:evidence_infer_treatment\\',\\n \\'huggingface:exams\\',\\n \\'huggingface:factckbr\\',\\n \\'huggingface:fake_news_english\\',\\n \\'huggingface:fake_news_filipino\\',\\n \\'huggingface:farsi_news\\',\\n \\'huggingface:fashion_mnist\\',\\n \\'huggingface:fever\\',\\n \\'huggingface:few_rel\\',\\n \\'huggingface:financial_phrasebank\\',\\n \\'huggingface:finer\\',\\n \\'huggingface:flores\\',\\n \\'huggingface:flue\\',\\n \\'huggingface:food101\\',\\n \\'huggingface:fquad\\',\\n \\'huggingface:freebase_qa\\',\\n \\'huggingface:gap\\',\\n \\'huggingface:gem\\',\\n \\'huggingface:generated_reviews_enth\\',\\n \\'huggingface:generics_kb\\',\\n \\'huggingface:german_legal_entity_recognition\\',\\n \\'huggingface:germaner\\',\\n \\'huggingface:germeval_14\\',\\n \\'huggingface:giga_fren\\',\\n \\'huggingface:gigaword\\',\\n \\'huggingface:glucose\\',\\n \\'huggingface:glue\\',\\n \\'huggingface:gnad10\\',\\n \\'huggingface:go_emotions\\',\\n \\'huggingface:gooaq\\',\\n \\'huggingface:google_wellformed_query\\',\\n \\'huggingface:grail_qa\\',\\n \\'huggingface:great_code\\',\\n \\'huggingface:greek_legal_code\\',\\n \\'huggingface:gsm8k\\',\\n \\'huggingface:guardian_authorship\\',\\n \\'huggingface:gutenberg_time\\',\\n \\'huggingface:hans\\',\\n \\'huggingface:hansards\\',\\n \\'huggingface:hard\\',\\n \\'huggingface:harem\\',\\n \\'huggingface:has_part\\',\\n \\'huggingface:hate_offensive\\',\\n \\'huggingface:hate_speech18\\',\\n \\'huggingface:hate_speech_filipino\\',\\n \\'huggingface:hate_speech_offensive\\',\\n \\'huggingface:hate_speech_pl\\',\\n \\'huggingface:hate_speech_portuguese\\',\\n \\'huggingface:hatexplain\\',\\n \\'huggingface:hausa_voa_ner\\',\\n \\'huggingface:hausa_voa_topics\\',\\n \\'huggingface:hda_nli_hindi\\',\\n \\'huggingface:head_qa\\',\\n \\'huggingface:health_fact\\',\\n \\'huggingface:hebrew_projectbenyehuda\\',\\n \\'huggingface:hebrew_sentiment\\',\\n \\'huggingface:hebrew_this_world\\',\\n \\'huggingface:hellaswag\\',\\n \\'huggingface:hendrycks_test\\',\\n \\'huggingface:hind_encorp\\',\\n \\'huggingface:hindi_discourse\\',\\n \\'huggingface:hippocorpus\\',\\n \\'huggingface:hkcancor\\',\\n \\'huggingface:hlgd\\',\\n \\'huggingface:hope_edi\\',\\n \\'huggingface:hotpot_qa\\',\\n \\'huggingface:hover\\',\\n \\'huggingface:hrenwac_para\\',\\n \\'huggingface:hrwac\\',\\n \\'huggingface:humicroedit\\',\\n \\'huggingface:hybrid_qa\\',\\n \\'huggingface:hyperpartisan_news_detection\\',\\n \\'huggingface:iapp_wiki_qa_squad\\',\\n \\'huggingface:id_clickbait\\',\\n \\'huggingface:id_liputan6\\',\\n \\'huggingface:id_nergrit_corpus\\',\\n \\'huggingface:id_newspapers_2018\\',\\n \\'huggingface:id_panl_bppt\\',\\n \\'huggingface:id_puisi\\',\\n \\'huggingface:igbo_english_machine_translation\\',\\n \\'huggingface:igbo_monolingual\\',\\n \\'huggingface:igbo_ner\\',\\n \\'huggingface:ilist\\',\\n \\'huggingface:imagenet-1k\\',\\n \\'huggingface:imagenet_sketch\\',\\n \\'huggingface:imdb\\',\\n \\'huggingface:imdb_urdu_reviews\\',\\n \\'huggingface:imppres\\',\\n \\'huggingface:indic_glue\\',\\n \\'huggingface:indonli\\',\\n \\'huggingface:indonlu\\',\\n \\'huggingface:inquisitive_qg\\',\\n \\'huggingface:interpress_news_category_tr\\',\\n \\'huggingface:interpress_news_category_tr_lite\\',\\n \\'huggingface:irc_disentangle\\',\\n \\'huggingface:isixhosa_ner_corpus\\',\\n \\'huggingface:isizulu_ner_corpus\\',\\n \\'huggingface:iwslt2017\\',\\n \\'huggingface:jeopardy\\',\\n \\'huggingface:jfleg\\',\\n \\'huggingface:jigsaw_toxicity_pred\\',\\n \\'huggingface:jigsaw_unintended_bias\\',\\n \\'huggingface:jnlpba\\',\\n \\'huggingface:journalists_questions\\',\\n \\'huggingface:kan_hope\\',\\n \\'huggingface:kannada_news\\',\\n \\'huggingface:kd_conv\\',\\n \\'huggingface:kde4\\',\\n \\'huggingface:kelm\\',\\n \\'huggingface:kilt_tasks\\',\\n \\'huggingface:kilt_wikipedia\\',\\n \\'huggingface:kinnews_kirnews\\',\\n \\'huggingface:klue\\',\\n \\'huggingface:kor_3i4k\\',\\n \\'huggingface:kor_hate\\',\\n \\'huggingface:kor_ner\\',\\n \\'huggingface:kor_nli\\',\\n \\'huggingface:kor_nlu\\',\\n \\'huggingface:kor_qpair\\',\\n \\'huggingface:kor_sae\\',\\n \\'huggingface:kor_sarcasm\\',\\n \\'huggingface:labr\\',\\n \\'huggingface:lama\\',\\n \\'huggingface:lambada\\',\\n \\'huggingface:large_spanish_corpus\\',\\n \\'huggingface:laroseda\\',\\n \\'huggingface:lc_quad\\',\\n \\'huggingface:lccc\\',\\n \\'huggingface:lener_br\\',\\n \\'huggingface:lex_glue\\',\\n \\'huggingface:liar\\',\\n \\'huggingface:librispeech_asr\\',\\n \\'huggingface:librispeech_lm\\',\\n \\'huggingface:limit\\',\\n \\'huggingface:lince\\',\\n \\'huggingface:linnaeus\\',\\n \\'huggingface:liveqa\\',\\n \\'huggingface:lj_speech\\',\\n \\'huggingface:lm1b\\',\\n \\'huggingface:lst20\\',\\n \\'huggingface:m_lama\\',\\n \\'huggingface:mac_morpho\\',\\n \\'huggingface:makhzan\\',\\n \\'huggingface:masakhaner\\',\\n \\'huggingface:math_dataset\\',\\n \\'huggingface:math_qa\\',\\n \\'huggingface:matinf\\',\\n \\'huggingface:mbpp\\',\\n \\'huggingface:mc4\\',\\n \\'huggingface:mc_taco\\',\\n \\'huggingface:md_gender_bias\\',\\n \\'huggingface:mdd\\',\\n \\'huggingface:med_hop\\',\\n \\'huggingface:medal\\',\\n \\'huggingface:medical_dialog\\',\\n \\'huggingface:medical_questions_pairs\\',\\n \\'huggingface:medmcqa\\',\\n \\'huggingface:menyo20k_mt\\',\\n \\'huggingface:meta_woz\\',\\n \\'huggingface:metashift\\',\\n \\'huggingface:metooma\\',\\n \\'huggingface:metrec\\',\\n \\'huggingface:miam\\',\\n \\'huggingface:mkb\\',\\n \\'huggingface:mkqa\\',\\n \\'huggingface:mlqa\\',\\n \\'huggingface:mlsum\\',\\n \\'huggingface:mnist\\',\\n \\'huggingface:mocha\\',\\n \\'huggingface:monash_tsf\\',\\n \\'huggingface:moroco\\',\\n \\'huggingface:movie_rationales\\',\\n \\'huggingface:mrqa\\',\\n \\'huggingface:ms_marco\\',\\n \\'huggingface:ms_terms\\',\\n \\'huggingface:msr_genomics_kbcomp\\',\\n \\'huggingface:msr_sqa\\',\\n \\'huggingface:msr_text_compression\\',\\n \\'huggingface:msr_zhen_translation_parity\\',\\n \\'huggingface:msra_ner\\',\\n \\'huggingface:mt_eng_vietnamese\\',\\n \\'huggingface:muchocine\\',\\n \\'huggingface:multi_booked\\',\\n \\'huggingface:multi_eurlex\\',\\n \\'huggingface:multi_news\\',\\n \\'huggingface:multi_nli\\',\\n \\'huggingface:multi_nli_mismatch\\',\\n \\'huggingface:multi_para_crawl\\',\\n \\'huggingface:multi_re_qa\\',\\n \\'huggingface:multi_woz_v22\\',\\n \\'huggingface:multi_x_science_sum\\',\\n \\'huggingface:multidoc2dial\\',\\n \\'huggingface:multilingual_librispeech\\',\\n \\'huggingface:mutual_friends\\',\\n \\'huggingface:mwsc\\',\\n \\'huggingface:myanmar_news\\',\\n \\'huggingface:narrativeqa\\',\\n \\'huggingface:narrativeqa_manual\\',\\n \\'huggingface:natural_questions\\',\\n \\'huggingface:ncbi_disease\\',\\n \\'huggingface:nchlt\\',\\n \\'huggingface:ncslgr\\',\\n \\'huggingface:nell\\',\\n \\'huggingface:neural_code_search\\',\\n \\'huggingface:news_commentary\\',\\n \\'huggingface:newsgroup\\',\\n \\'huggingface:newsph\\',\\n \\'huggingface:newsph_nli\\',\\n \\'huggingface:newspop\\',\\n \\'huggingface:newsqa\\',\\n \\'huggingface:newsroom\\',\\n \\'huggingface:nkjp-ner\\',\\n \\'huggingface:nli_tr\\',\\n \\'huggingface:nlu_evaluation_data\\',\\n \\'huggingface:norec\\',\\n \\'huggingface:norne\\',\\n \\'huggingface:norwegian_ner\\',\\n \\'huggingface:nq_open\\',\\n \\'huggingface:nsmc\\',\\n \\'huggingface:numer_sense\\',\\n \\'huggingface:numeric_fused_head\\',\\n \\'huggingface:oclar\\',\\n \\'huggingface:offcombr\\',\\n \\'huggingface:offenseval2020_tr\\',\\n \\'huggingface:offenseval_dravidian\\',\\n \\'huggingface:ofis_publik\\',\\n \\'huggingface:ohsumed\\',\\n \\'huggingface:ollie\\',\\n \\'huggingface:omp\\',\\n \\'huggingface:onestop_english\\',\\n \\'huggingface:onestop_qa\\',\\n \\'huggingface:open_subtitles\\',\\n \\'huggingface:openai_humaneval\\',\\n \\'huggingface:openbookqa\\',\\n \\'huggingface:openslr\\',\\n \\'huggingface:openwebtext\\',\\n \\'huggingface:opinosis\\',\\n \\'huggingface:opus100\\',\\n \\'huggingface:opus_books\\',\\n \\'huggingface:opus_dgt\\',\\n \\'huggingface:opus_dogc\\',\\n \\'huggingface:opus_elhuyar\\',\\n \\'huggingface:opus_euconst\\',\\n \\'huggingface:opus_finlex\\',\\n \\'huggingface:opus_fiskmo\\',\\n \\'huggingface:opus_gnome\\',\\n \\'huggingface:opus_infopankki\\',\\n \\'huggingface:opus_memat\\',\\n \\'huggingface:opus_montenegrinsubs\\',\\n \\'huggingface:opus_openoffice\\',\\n \\'huggingface:opus_paracrawl\\',\\n \\'huggingface:opus_rf\\',\\n \\'huggingface:opus_tedtalks\\',\\n \\'huggingface:opus_ubuntu\\',\\n \\'huggingface:opus_wikipedia\\',\\n \\'huggingface:opus_xhosanavy\\',\\n \\'huggingface:orange_sum\\',\\n \\'huggingface:oscar\\',\\n \\'huggingface:para_crawl\\',\\n \\'huggingface:para_pat\\',\\n \\'huggingface:parsinlu_reading_comprehension\\',\\n \\'huggingface:pass\\',\\n \\'huggingface:paws\\',\\n \\'huggingface:paws-x\\',\\n \\'huggingface:pec\\',\\n \\'huggingface:peer_read\\',\\n \\'huggingface:peoples_daily_ner\\',\\n \\'huggingface:per_sent\\',\\n \\'huggingface:persian_ner\\',\\n \\'huggingface:pg19\\',\\n \\'huggingface:php\\',\\n \\'huggingface:piaf\\',\\n \\'huggingface:pib\\',\\n \\'huggingface:piqa\\',\\n \\'huggingface:pn_summary\\',\\n \\'huggingface:poem_sentiment\\',\\n \\'huggingface:polemo2\\',\\n \\'huggingface:poleval2019_cyberbullying\\',\\n \\'huggingface:poleval2019_mt\\',\\n \\'huggingface:polsum\\',\\n \\'huggingface:polyglot_ner\\',\\n \\'huggingface:prachathai67k\\',\\n \\'huggingface:pragmeval\\',\\n \\'huggingface:proto_qa\\',\\n \\'huggingface:psc\\',\\n \\'huggingface:ptb_text_only\\',\\n \\'huggingface:pubmed\\',\\n \\'huggingface:pubmed_qa\\',\\n \\'huggingface:py_ast\\',\\n \\'huggingface:qa4mre\\',\\n \\'huggingface:qa_srl\\',\\n \\'huggingface:qa_zre\\',\\n \\'huggingface:qangaroo\\',\\n \\'huggingface:qanta\\',\\n \\'huggingface:qasc\\',\\n \\'huggingface:qasper\\',\\n \\'huggingface:qed\\',\\n \\'huggingface:qed_amara\\',\\n \\'huggingface:quac\\',\\n \\'huggingface:quail\\',\\n \\'huggingface:quarel\\',\\n \\'huggingface:quartz\\',\\n \\'huggingface:quickdraw\\',\\n \\'huggingface:quora\\',\\n \\'huggingface:quoref\\',\\n \\'huggingface:race\\',\\n \\'huggingface:re_dial\\',\\n \\'huggingface:reasoning_bg\\',\\n \\'huggingface:recipe_nlg\\',\\n \\'huggingface:reclor\\',\\n \\'huggingface:red_caps\\',\\n \\'huggingface:reddit\\',\\n \\'huggingface:reddit_tifu\\',\\n \\'huggingface:refresd\\',\\n \\'huggingface:reuters21578\\',\\n \\'huggingface:riddle_sense\\',\\n \\'huggingface:ro_sent\\',\\n \\'huggingface:ro_sts\\',\\n \\'huggingface:ro_sts_parallel\\',\\n \\'huggingface:roman_urdu\\',\\n \\'huggingface:roman_urdu_hate_speech\\',\\n \\'huggingface:ronec\\',\\n \\'huggingface:ropes\\',\\n \\'huggingface:rotten_tomatoes\\',\\n \\'huggingface:russian_super_glue\\',\\n \\'huggingface:rvl_cdip\\',\\n \\'huggingface:s2orc\\',\\n \\'huggingface:samsum\\',\\n \\'huggingface:sanskrit_classic\\',\\n \\'huggingface:saudinewsnet\\',\\n \\'huggingface:sberquad\\',\\n \\'huggingface:sbu_captions\\',\\n \\'huggingface:scan\\',\\n \\'huggingface:scb_mt_enth_2020\\',\\n \\'huggingface:scene_parse_150\\',\\n \\'huggingface:schema_guided_dstc8\\',\\n \\'huggingface:scicite\\',\\n \\'huggingface:scielo\\',\\n \\'huggingface:scientific_papers\\',\\n \\'huggingface:scifact\\',\\n \\'huggingface:sciq\\',\\n \\'huggingface:scitail\\',\\n \\'huggingface:scitldr\\',\\n \\'huggingface:search_qa\\',\\n \\'huggingface:sede\\',\\n \\'huggingface:selqa\\',\\n \\'huggingface:sem_eval_2010_task_8\\',\\n \\'huggingface:sem_eval_2014_task_1\\',\\n \\'huggingface:sem_eval_2018_task_1\\',\\n \\'huggingface:sem_eval_2020_task_11\\',\\n \\'huggingface:sent_comp\\',\\n \\'huggingface:senti_lex\\',\\n \\'huggingface:senti_ws\\',\\n \\'huggingface:sentiment140\\',\\n \\'huggingface:sepedi_ner\\',\\n \\'huggingface:sesotho_ner_corpus\\',\\n \\'huggingface:setimes\\',\\n \\'huggingface:setswana_ner_corpus\\',\\n \\'huggingface:sharc\\',\\n \\'huggingface:sharc_modified\\',\\n \\'huggingface:sick\\',\\n \\'huggingface:silicone\\',\\n \\'huggingface:simple_questions_v2\\',\\n \\'huggingface:siswati_ner_corpus\\',\\n \\'huggingface:smartdata\\',\\n \\'huggingface:sms_spam\\',\\n \\'huggingface:snips_built_in_intents\\',\\n \\'huggingface:snli\\',\\n \\'huggingface:snow_simplified_japanese_corpus\\',\\n \\'huggingface:so_stacksample\\',\\n \\'huggingface:social_bias_frames\\',\\n \\'huggingface:social_i_qa\\',\\n \\'huggingface:sofc_materials_articles\\',\\n ...]\\n\\nLoad a dataset\\ntfds.load\\nThe easiest way of loading a dataset is tfds.load. It will:\\n\\nDownload the data and save it as tfrecord files.\\nLoad the tfrecord and create the tf.data.Dataset.\\n\\nds = tfds.load(\\'mnist\\', split=\\'train\\', shuffle_files=True)\\nassert isinstance(ds, tf.data.Dataset)\\nprint(ds)\\n\\n\\n<_PrefetchDataset element_spec={\\'image\\': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), \\'label\\': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\\n2024-12-14 12:41:58.857496: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\\n\\nSome common arguments:\\n\\nsplit=: Which split to read (e.g. \\'train\\', [\\'train\\', \\'test\\'], \\'train[80%:]\\',...). See our split API guide.\\nshuffle_files=: Control whether to shuffle the files between each epoch (TFDS store big datasets in multiple smaller files).\\ndata_dir=: Location where the dataset is saved (\\ndefaults to ~/tensorflow_datasets/)\\nwith_info=True: Returns the tfds.core.DatasetInfo containing dataset metadata\\ndownload=False: Disable download\\n\\ntfds.builder\\ntfds.load is a thin wrapper around tfds.core.DatasetBuilder. You can get the same output using the tfds.core.DatasetBuilder API:\\nbuilder = tfds.builder(\\'mnist\\')\\n# 1. Create the tfrecord files (no-op if already exists)\\nbuilder.download_and_prepare()\\n# 2. Load the `tf.data.Dataset`\\nds = builder.as_dataset(split=\\'train\\', shuffle_files=True)\\nprint(ds)\\n\\n\\n<_PrefetchDataset element_spec={\\'image\\': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), \\'label\\': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\\n\\ntfds build CLI\\nIf you want to generate a specific dataset, you can use the tfds command line. For example:\\ntfds build mnist\\n\\nSee the doc for available flags.\\nIterate over a dataset\\nAs dict\\nBy default, the tf.data.Dataset object contains a dict of tf.Tensors:\\nds = tfds.load(\\'mnist\\', split=\\'train\\')\\nds = ds.take(1)  # Only take a single example\\n\\nfor example in ds:  # example is `{\\'image\\': tf.Tensor, \\'label\\': tf.Tensor}`\\n  print(list(example.keys()))\\n  image = example[\"image\"]\\n  label = example[\"label\"]\\n  print(image.shape, label)\\n\\n\\n[\\'image\\', \\'label\\']\\n(28, 28, 1) tf.Tensor(4, shape=(), dtype=int64)\\n2024-12-14 12:42:00.177868: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\\n\\nTo find out the dict key names and structure, look at the dataset documentation in our catalog. For example: mnist documentation.\\nAs tuple (as_supervised=True)\\nBy using as_supervised=True, you can get a tuple (features, label) instead for supervised datasets.\\nds = tfds.load(\\'mnist\\', split=\\'train\\', as_supervised=True)\\nds = ds.take(1)\\n\\nfor image, label in ds:  # example is (image, label)\\n  print(image.shape, label)\\n\\n\\n(28, 28, 1) tf.Tensor(4, shape=(), dtype=int64)\\n2024-12-14 12:42:01.224313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\\n\\nAs numpy (tfds.as_numpy)\\nUses tfds.as_numpy to convert:\\n\\ntf.Tensor -> np.array\\ntf.data.Dataset -> Iterator[Tree[np.array]] (Tree can be arbitrary nested Dict, Tuple)\\n\\nds = tfds.load(\\'mnist\\', split=\\'train\\', as_supervised=True)\\nds = ds.take(1)\\n\\nfor image, label in tfds.as_numpy(ds):\\n  print(type(image), type(label), label)\\n\\n\\n<class \\'numpy.ndarray\\'> <class \\'numpy.int64\\'> 4\\n2024-12-14 12:42:02.065492: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\\n\\nAs batched tf.Tensor (batch_size=-1)\\nBy using batch_size=-1, you can load the full dataset in a single batch.\\nThis can be combined with as_supervised=True and tfds.as_numpy to get the the data as (np.array, np.array):\\nimage, label = tfds.as_numpy(tfds.load(\\n    \\'mnist\\',\\n    split=\\'test\\',\\n    batch_size=-1,\\n    as_supervised=True,\\n))\\n\\nprint(type(image), image.shape)\\n\\n\\n<class \\'numpy.ndarray\\'> (10000, 28, 28, 1)\\n\\nBe careful that your dataset can fit in memory, and that all examples have the same shape.\\nBenchmark your datasets\\nBenchmarking a dataset is a simple tfds.benchmark call on any iterable (e.g. tf.data.Dataset, tfds.as_numpy,...).\\nds = tfds.load(\\'mnist\\', split=\\'train\\')\\nds = ds.batch(32).prefetch(1)\\n\\ntfds.benchmark(ds, batch_size=32)\\ntfds.benchmark(ds, batch_size=32)  # Second epoch much faster due to auto-caching\\n\\n\\n************ Summary ************\\n\\nExamples/sec (First included) 45061.33 ex/sec (total: 60032 ex, 1.33 sec)\\nExamples/sec (First only) 72.23 ex/sec (total: 32 ex, 0.44 sec)\\nExamples/sec (First excluded) 67477.64 ex/sec (total: 60000 ex, 0.89 sec)\\n\\n************ Summary ************\\n\\nExamples/sec (First included) 199832.93 ex/sec (total: 60032 ex, 0.30 sec)\\nExamples/sec (First only) 2367.04 ex/sec (total: 32 ex, 0.01 sec)\\nExamples/sec (First excluded) 209137.96 ex/sec (total: 60000 ex, 0.29 sec)\\n\\n\\n\\nDo not forget to normalize the results per batch size with the batch_size= kwarg.\\nIn the summary, the first warmup batch is separated from the other ones to capture tf.data.Dataset extra setup time (e.g. buffers initialization,...).\\nNotice how the second iteration is much faster due to TFDS auto-caching.\\ntfds.benchmark returns a tfds.core.BenchmarkResult which can be inspected for further analysis.\\n\\nBuild end-to-end pipeline\\nTo go further, you can look:\\n\\nOur end-to-end Keras example to see a full training pipeline (with batching, shuffling,...).\\nOur performance guide to improve the speed of your pipelines (tip: use tfds.benchmark(ds) to benchmark your datasets).\\n\\nVisualization\\ntfds.as_dataframe\\ntf.data.Dataset objects can be converted to pandas.DataFrame with tfds.as_dataframe to be visualized on Colab.\\n\\nAdd the tfds.core.DatasetInfo as second argument of tfds.as_dataframe to visualize images, audio, texts, videos,...\\nUse ds.take(x) to only display the first x examples. pandas.DataFrame will load the full dataset in-memory, and can be very expensive to display.\\n\\nds, info = tfds.load(\\'mnist\\', split=\\'train\\', with_info=True)\\n\\ntfds.as_dataframe(ds.take(4), info)\\n\\n\\n2024-12-14 12:42:05.775782: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\\n\\n\\ntfds.show_examples\\ntfds.show_examples returns a matplotlib.figure.Figure (only image datasets supported now):\\nds, info = tfds.load(\\'mnist\\', split=\\'train\\', with_info=True)\\n\\nfig = tfds.show_examples(ds, info)\\n\\n\\n2024-12-14 12:42:06.859043: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\\n\\n\\nAccess the dataset metadata\\nAll builders include a tfds.core.DatasetInfo object containing the dataset metadata.\\nIt can be accessed through:\\n\\nThe tfds.load API:\\n\\nds, info = tfds.load(\\'mnist\\', with_info=True)\\n\\n\\nThe tfds.core.DatasetBuilder API:\\n\\nbuilder = tfds.builder(\\'mnist\\')\\ninfo = builder.info\\n\\nThe dataset info contains additional informations about the dataset (version, citation, homepage, description,...).\\nprint(info)\\n\\n\\ntfds.core.DatasetInfo(\\n    name=\\'mnist\\',\\n    full_name=\\'mnist/3.0.1\\',\\n    description=\"\"\"\\n    The MNIST database of handwritten digits.\\n    \"\"\",\\n    homepage=\\'http://yann.lecun.com/exdb/mnist/\\',\\n    data_dir=\\'gs://tensorflow-datasets/datasets/mnist/3.0.1\\',\\n    file_format=tfrecord,\\n    download_size=11.06 MiB,\\n    dataset_size=21.00 MiB,\\n    features=FeaturesDict({\\n        \\'image\\': Image(shape=(28, 28, 1), dtype=uint8),\\n        \\'label\\': ClassLabel(shape=(), dtype=int64, num_classes=10),\\n    }),\\n    supervised_keys=(\\'image\\', \\'label\\'),\\n    disable_shuffling=False,\\n    splits={\\n        \\'test\\': <SplitInfo num_examples=10000, num_shards=1>,\\n        \\'train\\': <SplitInfo num_examples=60000, num_shards=1>,\\n    },\\n    citation=\"\"\"@article{lecun2010mnist,\\n      title={MNIST handwritten digit database},\\n      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\\n      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\\n      volume={2},\\n      year={2010}\\n    }\"\"\",\\n)\\n\\nFeatures metadata (label names, image shape,...)\\nAccess the tfds.features.FeatureDict:\\ninfo.features\\n\\n\\nFeaturesDict({\\n    \\'image\\': Image(shape=(28, 28, 1), dtype=uint8),\\n    \\'label\\': ClassLabel(shape=(), dtype=int64, num_classes=10),\\n})\\n\\nNumber of classes, label names:\\nprint(info.features[\"label\"].num_classes)\\nprint(info.features[\"label\"].names)\\nprint(info.features[\"label\"].int2str(7))  # Human readable version (8 -> \\'cat\\')\\nprint(info.features[\"label\"].str2int(\\'7\\'))\\n\\n\\n10\\n[\\'0\\', \\'1\\', \\'2\\', \\'3\\', \\'4\\', \\'5\\', \\'6\\', \\'7\\', \\'8\\', \\'9\\']\\n7\\n7\\n\\nShapes, dtypes:\\nprint(info.features.shape)\\nprint(info.features.dtype)\\nprint(info.features[\\'image\\'].shape)\\nprint(info.features[\\'image\\'].dtype)\\n\\n\\nWARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\\nWARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\\n{\\'image\\': (28, 28, 1), \\'label\\': ()}\\n{\\'image\\': tf.uint8, \\'label\\': tf.int64}\\n(28, 28, 1)\\n<dtype: \\'uint8\\'>\\n\\nSplit metadata (e.g. split names, number of examples,...)\\nAccess the tfds.core.SplitDict:\\nprint(info.splits)\\n\\n\\n{\\'test\\': <SplitInfo num_examples=10000, num_shards=1>, \\'train\\': <SplitInfo num_examples=60000, num_shards=1>}\\n\\nAvailable splits:\\nprint(list(info.splits.keys()))\\n\\n\\n[\\'test\\', \\'train\\']\\n\\nGet info on individual split:\\nprint(info.splits[\\'train\\'].num_examples)\\nprint(info.splits[\\'train\\'].filenames)\\nprint(info.splits[\\'train\\'].num_shards)\\n\\n\\n60000\\n[\\'mnist-train.tfrecord-00000-of-00001\\']\\n1\\n\\nIt also works with the subsplit API:\\nprint(info.splits[\\'train[15%:75%]\\'].num_examples)\\nprint(info.splits[\\'train[15%:75%]\\'].file_instructions)\\n\\n\\n36000\\n[FileInstruction(filename=\\'gs://tensorflow-datasets/datasets/mnist/3.0.1/mnist-train.tfrecord-00000-of-00001\\', skip=9000, take=36000, examples_in_shard=60000)]\\n\\nTroubleshooting\\nManual download (if download fails)\\nIf download fails for some reason (e.g. offline,...). You can always manually download the data yourself and place it in the manual_dir (defaults to ~/tensorflow_datasets/downloads/manual/.\\nTo find out which urls to download, look into:\\n\\nFor new datasets (implemented as folder): tensorflow_datasets/<type>/<dataset_name>/checksums.tsv. For example: tensorflow_datasets/datasets/bool_q/checksums.tsv.\\nYou can find the dataset source location in our catalog.\\nFor old datasets: tensorflow_datasets/url_checksums/<dataset_name>.txt\\n\\nFixing NonMatchingChecksumError\\nTFDS ensure determinism by validating the checksums of downloaded urls.\\nIf NonMatchingChecksumError is raised, might indicate:\\n\\nThe website may be down (e.g. 503 status code). Please check the url.\\nFor Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See bug\\nThe original datasets files may have been updated. In this case the TFDS dataset builder should be updated. Please open a new Github issue or PR:\\n\\nRegister the new checksums with tfds build --register_checksums\\nEventually update the dataset generation code.\\nUpdate the dataset VERSION\\nUpdate the dataset RELEASE_NOTES: What caused the checksums to change ? Did some examples changed ?\\nMake sure the dataset can still be built.\\nSend us a PR\\n\\n\\nNote: You can also inspect the downloaded file in ~/tensorflow_datasets/download/.\\nCitation\\nIf you\\'re using tensorflow-datasets for a paper, please include the following citation, in addition to any citation specific to the used datasets (which can be found in the dataset catalog).\\n@misc{TFDS,\\n  title = { {TensorFlow Datasets}, A collection of ready-to-use datasets},\\n  howpublished = {\\\\url{https://www.tensorflow.org/datasets} },\\n}\\n\\n\\n\\n\\n\\n\\n\\n\\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\\nLast updated 2024-12-14 UTC.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStay connected\\n\\n\\n\\n            \\n          \\n            Blog\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Forum\\n          \\n          \\n\\n\\n\\n            \\n          \\n            GitHub\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Twitter\\n          \\n          \\n\\n\\n\\n            \\n              \\n              \\n            \\n          \\n            YouTube\\n          \\n          \\n\\n\\n\\n\\nSupport\\n\\n\\n\\n            \\n          \\n            Issue tracker\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Release notes\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Stack Overflow\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Brand guidelines\\n          \\n          \\n\\n\\n\\n            \\n              \\n              \\n            \\n          \\n            Cite TensorFlow\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Terms\\n        \\n\\n\\n\\n          Privacy\\n        \\n\\n\\n\\n          Manage cookies\\n        \\n\\n\\nSign up for the TensorFlow newsletter\\n\\n          Subscribe\\n        \\n\\n\\n\\n\\n\\nEnglish\\n\\n\\nEspa√±ol ‚Äì Am√©rica Latina\\n\\n\\nFran√ßais\\n\\n\\nIndonesia\\n\\n\\nItaliano\\n\\n\\nPolski\\n\\n\\nPortugu√™s ‚Äì Brasil\\n\\n\\nTi√™ÃÅng Vi√™Ã£t\\n\\n\\nT√ºrk√ße\\n\\n\\n–†—É—Å—Å–∫–∏–π\\n\\n\\n◊¢◊ë◊®◊ô◊™\\n\\n\\nÿßŸÑÿπÿ±ÿ®ŸäŸëÿ©\\n\\n\\nŸÅÿßÿ±ÿ≥€å\\n\\n\\n‡§π‡§ø‡§Ç‡§¶‡•Ä\\n\\n\\n‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ\\n\\n\\n‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\\n\\n\\n‰∏≠Êñá ‚Äì ÁÆÄ‰Ωì\\n\\n\\nÊó•Êú¨Ë™û\\n\\n\\nÌïúÍµ≠Ïñ¥\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://www.tensorflow.org/hub/tutorials/tf2_object_detection', 'title': 'TensorFlow Hub Object Detection Colab', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTensorFlow Hub Object Detection Colab\\n\\n\\n\\n\\n\\n\\n\\n      \\n      Skip to main content\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Install\\n  \\n    \\n\\n\\n\\n    Learn\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      Introduction\\n                    \\n\\n                      New to TensorFlow?\\n                    \\n\\n\\n\\n\\n\\n                      Tutorials\\n                    \\n\\n                      Learn how to use TensorFlow with end-to-end examples\\n                    \\n\\n\\n\\n\\n\\n                      Guide\\n                    \\n\\n                      Learn framework concepts and components\\n                    \\n\\n\\n\\n\\n\\n                      Learn ML\\n                    \\n\\n                      Educational resources to master your path with TensorFlow\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    API\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      TensorFlow (v2.16.1)\\n                    \\n\\n\\n\\n\\n\\n                      Versions…\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                      TensorFlow.js\\n                    \\n\\n\\n\\n\\n\\n                      TensorFlow Lite\\n                    \\n\\n\\n\\n\\n\\n                      TFX\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Resources\\n  \\n    \\n\\n\\n\\n\\n\\nLIBRARIES\\n\\n\\n\\n                      TensorFlow.js\\n                    \\n\\n                      Develop web ML applications in JavaScript\\n                    \\n\\n\\n\\n\\n\\n                      TensorFlow Lite\\n                    \\n\\n                      Deploy ML on mobile, microcontrollers and other edge devices\\n                    \\n\\n\\n\\n\\n\\n                      TFX\\n                    \\n\\n                      Build production ML pipelines\\n                    \\n\\n\\n\\n\\n\\n                      All libraries\\n                    \\n\\n                      Create advanced models and extend TensorFlow\\n                    \\n\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\n\\n                      Models & datasets\\n                    \\n\\n                      Pre-trained models and datasets built by Google and the community\\n                    \\n\\n\\n\\n\\n\\n                      Tools\\n                    \\n\\n                      Tools to support and accelerate TensorFlow workflows\\n                    \\n\\n\\n\\n\\n\\n                      Responsible AI\\n                    \\n\\n                      Resources for every stage of the ML workflow\\n                    \\n\\n\\n\\n\\n\\n                      Recommendation systems\\n                    \\n\\n                      Build recommendation systems with open source tools\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Community\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      Groups\\n                    \\n\\n                      User groups, interest groups and mailing lists\\n                    \\n\\n\\n\\n\\n\\n                      Contribute\\n                    \\n\\n                      Guide for contributing to code and documentation\\n                    \\n\\n\\n\\n\\n\\n                      Blog\\n                    \\n\\n                      Stay up to date with all things TensorFlow\\n                    \\n\\n\\n\\n\\n\\n                      Forum\\n                    \\n\\n                      Discussion platform for the TensorFlow community\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Why TensorFlow\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n                      About\\n                    \\n\\n\\n\\n\\n\\n                      Case studies\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n/\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n中文 – 简体\\n\\n\\n\\n\\n  GitHub\\n\\n\\nSign in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        Hub\\n      \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Overview\\n  \\n    \\n\\n\\n\\n    Guide\\n  \\n    \\n\\n\\n\\n    Tutorials\\n  \\n    \\n\\n\\n\\n    API\\n  \\n    \\n\\n\\n\\n    Models ↗\\n  \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Install\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Learn\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      API\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Resources\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Overview\\n   \\n\\n\\n\\n\\n\\n      Guide\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Tutorials\\n   \\n\\n\\n\\n\\n\\n\\n\\n      API\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Models ↗\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Community\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Why TensorFlow\\n   \\n\\n\\n\\n\\n\\n      More\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      GitHub\\n   \\n\\n\\n\\n\\n\\n\\n\\nGetting started\\n\\nOverview\\n\\nNLP Tutorials\\n\\nText classification\\nClassify text with BERT\\nBERT on TPU\\nReal-time semantic search\\nMultilingual question answering\\n\\n\\nAdditional NLP tutorials\\nBERT ExpertsSemantic similarityText classification on KaggleBangla article classifierExplore CORD-19 text embeddingsMultilingual universal sentence encoderText cookbookSentEval for Universal Sentence Encoder CMLM model.\\n\\nImage Tutorials\\n\\nImage classification\\nTransfer Learning for Image classification\\nStyle transfer\\nLarge-scale image retrieval with DELF\\nObject detection\\nGANs for image generation\\nHuman Pose Estimation\\n\\n\\nAdditional image tutorials\\nCropNet: Cassava Disease DetectionCropNet: Fine tuning models for on-device inferenceBoundless GANSuper resolutionHRNet model inference for semantic segmentation\\n\\nAudio Tutorials\\n\\nPitch recognition\\nSound classification\\nAutomatic speech recognition with Wav2Vec2\\n\\nVideo Tutorials\\n\\nFrame interpolation with FILM\\nAction recognition\\nStreaming action recognition\\nVideo interpolation\\nText-to-video retrieval\\n\\n\\nTutorials (TF1)\\n\\nImage Tutorials\\nImage classificationObject detectionBigGAN image generationBigBiGAN image generationS3 GAN image generation\\nNLP Tutorials\\nSemantic similarity liteNearest neighbor index for real-time semantic searchExplore CORD-19 text embeddingsWiki40B Language Models\\n\\n\\n\\n\\n\\n      Introduction\\n   \\n\\n\\n\\n\\n\\n      Tutorials\\n   \\n\\n\\n\\n\\n\\n      Guide\\n   \\n\\n\\n\\n\\n\\n      Learn ML\\n   \\n\\n\\n\\n\\n\\n\\n\\n      TensorFlow (v2.16.1)\\n   \\n\\n\\n\\n\\n\\n      Versions…\\n   \\n\\n\\n\\n\\n\\n      TensorFlow.js\\n   \\n\\n\\n\\n\\n\\n      TensorFlow Lite\\n   \\n\\n\\n\\n\\n\\n      TFX\\n   \\n\\n\\n\\n\\n\\n\\n\\n      LIBRARIES\\n   \\n\\n\\n\\n\\n\\n      TensorFlow.js\\n   \\n\\n\\n\\n\\n\\n      TensorFlow Lite\\n   \\n\\n\\n\\n\\n\\n      TFX\\n   \\n\\n\\n\\n\\n\\n      All libraries\\n   \\n\\n\\n\\n\\n\\n      RESOURCES\\n   \\n\\n\\n\\n\\n\\n      Models & datasets\\n   \\n\\n\\n\\n\\n\\n      Tools\\n   \\n\\n\\n\\n\\n\\n      Responsible AI\\n   \\n\\n\\n\\n\\n\\n      Recommendation systems\\n   \\n\\n\\n\\n\\n\\n\\n\\n      Groups\\n   \\n\\n\\n\\n\\n\\n      Contribute\\n   \\n\\n\\n\\n\\n\\n      Blog\\n   \\n\\n\\n\\n\\n\\n      Forum\\n   \\n\\n\\n\\n\\n\\n\\n\\n      About\\n   \\n\\n\\n\\n\\n\\n      Case studies\\n   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    \\n        TensorFlow\\n      \\n  \\n\\n\\n\\n\\n    \\n        Resources\\n      \\n  \\n\\n\\n\\n\\n    \\n        Hub\\n      \\n  \\n\\n\\n\\n\\n    \\n        Tutorials\\n      \\n  \\n\\n\\n\\n\\n\\n\\n      TensorFlow Hub Object Detection Colab\\n      \\n\\n\\n      \\n      Stay organized with collections\\n    \\n\\n      \\n      Save and categorize content based on your preferences.\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nView on TensorFlow.org\\n\\n\\nRun in Google Colab\\n\\n\\nView on GitHub\\n\\n\\nDownload notebook\\n\\n\\nSee TF Hub models\\n\\n\\nWelcome to the TensorFlow Hub Object Detection Colab! This notebook will take you through the steps of running an \"out-of-the-box\" object detection model on images.\\nMore models\\nThis collection contains TF2 object detection models that have been trained on the COCO 2017 dataset. Here you can find all object detection models that are currently hosted on tfhub.dev.\\nImports and Setup\\nLet\\'s start with the base imports.\\n# This Colab requires a recent numpy version.\\npip install numpy==1.24.3\\npip install protobuf==3.20.3\\nimport os\\nimport pathlib\\n\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\n\\nimport io\\nimport scipy.misc\\nimport numpy as np\\nfrom six import BytesIO\\nfrom PIL import Image, ImageDraw, ImageFont\\nfrom six.moves.urllib.request import urlopen\\n\\nimport tensorflow as tf\\nimport tensorflow_hub as hub\\n\\ntf.get_logger().setLevel(\\'ERROR\\')\\n\\nUtilities\\nRun the following cell to create some utils that will be needed later:\\n\\nHelper method to load an image\\nMap of Model Name to TF Hub handle\\nList of tuples with Human Keypoints for the COCO 2017 dataset. This is needed for models with keypoints.\\n\\n\\n\\nToggle code\\n# @title Run this!!\\n\\ndef load_image_into_numpy_array(path):\\n  \"\"\"Load an image from file into a numpy array.\\n\\n  Puts image into numpy array to feed into tensorflow graph.\\n  Note that by convention we put it into a numpy array with shape\\n  (height, width, channels), where channels=3 for RGB.\\n\\n  Args:\\n    path: the file path to the image\\n\\n  Returns:\\n    uint8 numpy array with shape (img_height, img_width, 3)\\n  \"\"\"\\n  image = None\\n  if(path.startswith(\\'http\\')):\\n    response = urlopen(path)\\n    image_data = response.read()\\n    image_data = BytesIO(image_data)\\n    image = Image.open(image_data)\\n  else:\\n    image_data = tf.io.gfile.GFile(path, \\'rb\\').read()\\n    image = Image.open(BytesIO(image_data))\\n\\n  (im_width, im_height) = image.size\\n  return np.array(image.getdata()).reshape(\\n      (1, im_height, im_width, 3)).astype(np.uint8)\\n\\n\\nALL_MODELS = {\\n\\'CenterNet HourGlass104 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1\\',\\n\\'CenterNet HourGlass104 Keypoints 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1\\',\\n\\'CenterNet HourGlass104 1024x1024\\' : \\'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1\\',\\n\\'CenterNet HourGlass104 Keypoints 1024x1024\\' : \\'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1\\',\\n\\'CenterNet Resnet50 V1 FPN 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1\\',\\n\\'CenterNet Resnet50 V1 FPN Keypoints 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1\\',\\n\\'CenterNet Resnet101 V1 FPN 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1\\',\\n\\'CenterNet Resnet50 V2 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1\\',\\n\\'CenterNet Resnet50 V2 Keypoints 512x512\\' : \\'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1\\',\\n\\'EfficientDet D0 512x512\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d0/1\\',\\n\\'EfficientDet D1 640x640\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d1/1\\',\\n\\'EfficientDet D2 768x768\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d2/1\\',\\n\\'EfficientDet D3 896x896\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d3/1\\',\\n\\'EfficientDet D4 1024x1024\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d4/1\\',\\n\\'EfficientDet D5 1280x1280\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d5/1\\',\\n\\'EfficientDet D6 1280x1280\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d6/1\\',\\n\\'EfficientDet D7 1536x1536\\' : \\'https://tfhub.dev/tensorflow/efficientdet/d7/1\\',\\n\\'SSD MobileNet v2 320x320\\' : \\'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\\',\\n\\'SSD MobileNet V1 FPN 640x640\\' : \\'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1\\',\\n\\'SSD MobileNet V2 FPNLite 320x320\\' : \\'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\\',\\n\\'SSD MobileNet V2 FPNLite 640x640\\' : \\'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1\\',\\n\\'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1\\',\\n\\'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1\\',\\n\\'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1\\',\\n\\'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1\\',\\n\\'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1\\',\\n\\'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)\\' : \\'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1\\',\\n\\'Faster R-CNN ResNet50 V1 640x640\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\\',\\n\\'Faster R-CNN ResNet50 V1 1024x1024\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1\\',\\n\\'Faster R-CNN ResNet50 V1 800x1333\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1\\',\\n\\'Faster R-CNN ResNet101 V1 640x640\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1\\',\\n\\'Faster R-CNN ResNet101 V1 1024x1024\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1\\',\\n\\'Faster R-CNN ResNet101 V1 800x1333\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1\\',\\n\\'Faster R-CNN ResNet152 V1 640x640\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1\\',\\n\\'Faster R-CNN ResNet152 V1 1024x1024\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1\\',\\n\\'Faster R-CNN ResNet152 V1 800x1333\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1\\',\\n\\'Faster R-CNN Inception ResNet V2 640x640\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\\',\\n\\'Faster R-CNN Inception ResNet V2 1024x1024\\' : \\'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1\\',\\n\\'Mask R-CNN Inception ResNet V2 1024x1024\\' : \\'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1\\'\\n}\\n\\nIMAGES_FOR_TEST = {\\n  \\'Beach\\' : \\'models/research/object_detection/test_images/image2.jpg\\',\\n  \\'Dogs\\' : \\'models/research/object_detection/test_images/image1.jpg\\',\\n  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\\n  \\'Naxos Taverna\\' : \\'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\\',\\n  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\\n  \\'Beatles\\' : \\'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg\\',\\n  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\\n  \\'Phones\\' : \\'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\\',\\n  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\\n  \\'Birds\\' : \\'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg\\',\\n}\\n\\nCOCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\\n (0, 2),\\n (1, 3),\\n (2, 4),\\n (0, 5),\\n (0, 6),\\n (5, 7),\\n (7, 9),\\n (6, 8),\\n (8, 10),\\n (5, 6),\\n (5, 11),\\n (6, 12),\\n (11, 12),\\n (11, 13),\\n (13, 15),\\n (12, 14),\\n (14, 16)]\\n\\n\\nVisualization tools\\nTo visualize the images with the proper detected boxes, keypoints and segmentation, we will use the TensorFlow Object Detection API. To install it we will clone the repo.\\n# Clone the tensorflow models repository\\ngit clone --depth 1 https://github.com/tensorflow/models\\n\\nCloning into \\'models\\'...\\nremote: Enumerating objects: 4084, done.\\nremote: Counting objects: 100% (4084/4084), done.\\nremote: Compressing objects: 100% (3076/3076), done.\\nremote: Total 4084 (delta 1188), reused 2898 (delta 948), pack-reused 0\\nReceiving objects: 100% (4084/4084), 44.61 MiB | 49.66 MiB/s, done.\\nResolving deltas: 100% (1188/1188), done.\\n\\nInstalling the Object Detection API\\nsudo apt install -y protobuf-compiler\\ncd models/research/\\nprotoc object_detection/protos/*.proto --python_out=.\\ncp object_detection/packages/tf2/setup.py .\\npython -m pip install .\\n\\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\\n\\ndpkg-preconfigure: unable to re-open stdin: No such file or directory\\n\\nNow we can import the dependencies we will need later\\nfrom object_detection.utils import label_map_util\\nfrom object_detection.utils import visualization_utils as viz_utils\\nfrom object_detection.utils import ops as utils_ops\\n\\n%matplotlib inline\\n\\nLoad label map data (for plotting).\\nLabel maps correspond index numbers to category names, so that when our convolution network predicts 5, we know that this corresponds to airplane.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine.\\nWe are going, for simplicity, to load from the repository that we loaded the Object Detection API code\\nPATH_TO_LABELS = \\'./models/research/object_detection/data/mscoco_label_map.pbtxt\\'\\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\\n\\nBuild a detection model and load pre-trained model weights\\nHere we will choose which Object Detection model we will use.\\nSelect the architecture and it will be loaded automatically.\\nIf you want to change the model to try other architectures later, just change the next cell and execute following ones.\\nTip: if you want to read more details about the selected model, you can follow the link (model handle) and read additional documentation on TF Hub. After you select a model, we will print the handle to make it easier.\\nModel Selection\\n\\n\\nToggle code\\nmodel_display_name = \\'CenterNet HourGlass104 Keypoints 512x512\\' # @param [\\'CenterNet HourGlass104 512x512\\',\\'CenterNet HourGlass104 Keypoints 512x512\\',\\'CenterNet HourGlass104 1024x1024\\',\\'CenterNet HourGlass104 Keypoints 1024x1024\\',\\'CenterNet Resnet50 V1 FPN 512x512\\',\\'CenterNet Resnet50 V1 FPN Keypoints 512x512\\',\\'CenterNet Resnet101 V1 FPN 512x512\\',\\'CenterNet Resnet50 V2 512x512\\',\\'CenterNet Resnet50 V2 Keypoints 512x512\\',\\'EfficientDet D0 512x512\\',\\'EfficientDet D1 640x640\\',\\'EfficientDet D2 768x768\\',\\'EfficientDet D3 896x896\\',\\'EfficientDet D4 1024x1024\\',\\'EfficientDet D5 1280x1280\\',\\'EfficientDet D6 1280x1280\\',\\'EfficientDet D7 1536x1536\\',\\'SSD MobileNet v2 320x320\\',\\'SSD MobileNet V1 FPN 640x640\\',\\'SSD MobileNet V2 FPNLite 320x320\\',\\'SSD MobileNet V2 FPNLite 640x640\\',\\'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\\',\\'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)\\',\\'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)\\',\\'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)\\',\\'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)\\',\\'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)\\',\\'Faster R-CNN ResNet50 V1 640x640\\',\\'Faster R-CNN ResNet50 V1 1024x1024\\',\\'Faster R-CNN ResNet50 V1 800x1333\\',\\'Faster R-CNN ResNet101 V1 640x640\\',\\'Faster R-CNN ResNet101 V1 1024x1024\\',\\'Faster R-CNN ResNet101 V1 800x1333\\',\\'Faster R-CNN ResNet152 V1 640x640\\',\\'Faster R-CNN ResNet152 V1 1024x1024\\',\\'Faster R-CNN ResNet152 V1 800x1333\\',\\'Faster R-CNN Inception ResNet V2 640x640\\',\\'Faster R-CNN Inception ResNet V2 1024x1024\\',\\'Mask R-CNN Inception ResNet V2 1024x1024\\']\\nmodel_handle = ALL_MODELS[model_display_name]\\n\\nprint(\\'Selected model:\\'+ model_display_name)\\nprint(\\'Model Handle at TensorFlow Hub: {}\\'.format(model_handle))\\n\\n\\n\\nSelected model:CenterNet HourGlass104 Keypoints 512x512\\nModel Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1\\n\\nLoading the selected model from TensorFlow Hub\\nHere we just need the model handle that was selected and use the Tensorflow Hub library to load it to memory.\\nprint(\\'loading model...\\')\\nhub_model = hub.load(model_handle)\\nprint(\\'model loaded!\\')\\n\\n\\nloading model...\\n2024-03-09 13:22:07.698952: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42408) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39751) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_encoder_decoder_block_layer_call_and_return_conditional_losses_191780) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_95722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_73_layer_call_and_return_conditional_losses_67031) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24349) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39306) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47074) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_55611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27222) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54225) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22353) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_55134) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31214) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52655) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28112) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45078) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43959) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49731) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46845) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28557) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29447) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21018) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_73_layer_call_and_return_conditional_losses_204261) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41747) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31443) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23014) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_36_layer_call_and_return_conditional_losses_66742) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38397) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40857) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51530) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_input_downsample_block_layer_call_and_return_conditional_losses_56840) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23904) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41963) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42637) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_224296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21908) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23230) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36363) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35702) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39967) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44633) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27451) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38181) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_56272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_71_layer_call_and_return_conditional_losses_77067) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_224056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50621) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38645) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36611) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46184) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39535) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32104) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_input_downsample_block_layer_call_and_return_conditional_losses_184458) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_encoder_decoder_block_5_layer_call_and_return_conditional_losses_73080) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27667) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_55382) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34113) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53100) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22798) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21247) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29002) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31659) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21463) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33223) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54689) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_72_layer_call_and_return_conditional_losses_66888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35454) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49960) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26345) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42192) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41531) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28786) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49286) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22124) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37952) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_21679) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_36_layer_call_and_return_conditional_losses_203862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25671) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48625) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_158598) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30553) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47290) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_38861) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24794) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26116) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_27006) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35238) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214936) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44188) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51746) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34793) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29663) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46400) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51282) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30782) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52191) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_56043) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_42853) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25900) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_41086) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_29218) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53348) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25010) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36147) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_35009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54473) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_hourglass_network_layer_call_and_return_conditional_losses_177444) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_217456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40641) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48180) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32549) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_215776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47951) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_39090) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_28341) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207496) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33668) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_72_layer_call_and_return_conditional_losses_204131) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223456) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_encoder_decoder_block_5_layer_call_and_return_conditional_losses_200628) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30337) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24565) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212296) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_center_net_hourglass_feature_extractor_layer_call_and_return_conditional_losses_120906) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_220696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_224176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_24120) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_36827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223216) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_34545) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25455) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_222736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_49515) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213616) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_51975) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_52439) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_encoder_decoder_block_layer_call_and_return_conditional_losses_62755) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_44849) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_residual_block_69_layer_call_and_return_conditional_losses_204469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_208096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_206656) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45523) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_53564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26561) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223696) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48396) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_48841) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_residual_block_69_layer_call_and_return_conditional_losses_67266) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50850) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218176) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_223096) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_50405) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_37272) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_209536) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219016) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47519) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54918) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_31888) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_210136) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_54009) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211816) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_46629) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_23675) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_convolutional_block_71_layer_call_and_return_conditional_losses_203998) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43527) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_40412) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_205576) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_214336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218776) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_22569) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_45294) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_221416) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_212056) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_32994) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_center_net_hourglass_feature_extractor_layer_call_and_return_conditional_losses_139752) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213856) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_207736) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43082) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_216376) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43743) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_43298) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_25226) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_33884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_26790) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_211336) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_47735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_30108) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_219256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_213976) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_218896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_55827) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nWARNING:absl:Importing a function (__inference_batchnorm_layer_call_and_return_conditional_losses_56488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\\nmodel loaded!\\n\\nLoading an image\\nLet\\'s try the model on a simple image. To help with this, we provide a list of test images.\\nHere are some simple things to try out if you are curious:\\n\\nTry running inference on your own images, just upload them to colab and load the same way it\\'s done in the cell below.\\nModify some of the input images and see if detection still works.  Some simple things to try out here include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).\\n\\nBe careful: when using images with an alpha channel, the model expect 3 channels images and the alpha will count as a 4th.\\nImage Selection (don\\'t forget to execute the cell!)\\n\\n\\nToggle code\\nselected_image = \\'Beach\\' # @param [\\'Beach\\', \\'Dogs\\', \\'Naxos Taverna\\', \\'Beatles\\', \\'Phones\\', \\'Birds\\']\\nflip_image_horizontally = False\\nconvert_image_to_grayscale = False\\n\\nimage_path = IMAGES_FOR_TEST[selected_image]\\nimage_np = load_image_into_numpy_array(image_path)\\n\\n# Flip horizontally\\nif(flip_image_horizontally):\\n  image_np[0] = np.fliplr(image_np[0]).copy()\\n\\n# Convert image to grayscale\\nif(convert_image_to_grayscale):\\n  image_np[0] = np.tile(\\n    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\\n\\nplt.figure(figsize=(24,32))\\nplt.imshow(image_np[0])\\nplt.show()\\n\\n\\n\\nDoing the inference\\nTo do the inference we just need to call our TF Hub loaded model.\\nThings you can try:\\n\\nPrint out result[\\'detection_boxes\\'] and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).\\ninspect other output keys present in the result. A full documentation can be seen on the models documentation page (pointing your browser to the model handle printed earlier)\\n\\n# running inference\\nresults = hub_model(image_np)\\n\\n# different object detection models have additional results\\n# all of them are explained in the documentation\\nresult = {key:value.numpy() for key,value in results.items()}\\nprint(result.keys())\\n\\n\\n2024-03-09 13:22:50.068692: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/cond/then/_918/cond/Assert_2/AssertGuard/branch_executed/_1123\\ndict_keys([\\'detection_scores\\', \\'detection_keypoints\\', \\'detection_keypoint_scores\\', \\'detection_boxes\\', \\'detection_classes\\', \\'num_detections\\'])\\n\\nVisualizing the results\\nHere is where we will need the TensorFlow Object Detection API to show the squares from the inference step (and the keypoints when available).\\nthe full documentation of this method can be seen here\\nHere you can, for example, set min_score_thresh to other values (between 0 and 1) to allow more detections in or to filter out more detections.\\nlabel_id_offset = 0\\nimage_np_with_detections = image_np.copy()\\n\\n# Use keypoints if available in detections\\nkeypoints, keypoint_scores = None, None\\nif \\'detection_keypoints\\' in result:\\n  keypoints = result[\\'detection_keypoints\\'][0]\\n  keypoint_scores = result[\\'detection_keypoint_scores\\'][0]\\n\\nviz_utils.visualize_boxes_and_labels_on_image_array(\\n      image_np_with_detections[0],\\n      result[\\'detection_boxes\\'][0],\\n      (result[\\'detection_classes\\'][0] + label_id_offset).astype(int),\\n      result[\\'detection_scores\\'][0],\\n      category_index,\\n      use_normalized_coordinates=True,\\n      max_boxes_to_draw=200,\\n      min_score_thresh=.30,\\n      agnostic_mode=False,\\n      keypoints=keypoints,\\n      keypoint_scores=keypoint_scores,\\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\\n\\nplt.figure(figsize=(24,32))\\nplt.imshow(image_np_with_detections[0])\\nplt.show()\\n\\n\\n[Optional]\\nAmong the available object detection models there\\'s Mask R-CNN and the output of this model allows instance segmentation.\\nTo visualize it we will use the same method we did before but adding an additional parameter: instance_masks=output_dict.get(\\'detection_masks_reframed\\', None)\\n# Handle models with masks:\\nimage_np_with_mask = image_np.copy()\\n\\nif \\'detection_masks\\' in result:\\n  # we need to convert np.arrays to tensors\\n  detection_masks = tf.convert_to_tensor(result[\\'detection_masks\\'][0])\\n  detection_boxes = tf.convert_to_tensor(result[\\'detection_boxes\\'][0])\\n\\n  # Reframe the bbox mask to the image size.\\n  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\\n            detection_masks, detection_boxes,\\n              image_np.shape[1], image_np.shape[2])\\n  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\\n                                      tf.uint8)\\n  result[\\'detection_masks_reframed\\'] = detection_masks_reframed.numpy()\\n\\nviz_utils.visualize_boxes_and_labels_on_image_array(\\n      image_np_with_mask[0],\\n      result[\\'detection_boxes\\'][0],\\n      (result[\\'detection_classes\\'][0] + label_id_offset).astype(int),\\n      result[\\'detection_scores\\'][0],\\n      category_index,\\n      use_normalized_coordinates=True,\\n      max_boxes_to_draw=200,\\n      min_score_thresh=.30,\\n      agnostic_mode=False,\\n      instance_masks=result.get(\\'detection_masks_reframed\\', None),\\n      line_thickness=8)\\n\\nplt.figure(figsize=(24,32))\\nplt.imshow(image_np_with_mask[0])\\nplt.show()\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\\nLast updated 2024-03-09 UTC.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nStay connected\\n\\n\\n\\n            \\n          \\n            Blog\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Forum\\n          \\n          \\n\\n\\n\\n            \\n          \\n            GitHub\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Twitter\\n          \\n          \\n\\n\\n\\n            \\n              \\n              \\n            \\n          \\n            YouTube\\n          \\n          \\n\\n\\n\\n\\nSupport\\n\\n\\n\\n            \\n          \\n            Issue tracker\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Release notes\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Stack Overflow\\n          \\n          \\n\\n\\n\\n            \\n          \\n            Brand guidelines\\n          \\n          \\n\\n\\n\\n            \\n              \\n              \\n            \\n          \\n            Cite TensorFlow\\n          \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Terms\\n        \\n\\n\\n\\n          Privacy\\n        \\n\\n\\n\\n          Manage cookies\\n        \\n\\n\\nSign up for the TensorFlow newsletter\\n\\n          Subscribe\\n        \\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n中文 – 简体\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "urls = set()\n",
    "for idx in top_indices[:2]:\n",
    "    urls.add(sublinks_tf[idx]['url'])\n",
    "loader = WebBaseLoader(list(urls))\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5928"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[0].page_content.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents[1].page_content.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1912 > 1106\n",
      "1958 > 869\n",
      "1790 > 516\n",
      "1829 > 222\n",
      "1997 > 105\n",
      "1995 > 112\n",
      "1997 > 107\n",
      "1996 > 94\n",
      "1997 > 73\n",
      "1988 > 63\n",
      "1985 > 71\n",
      "1981 > 70\n",
      "1985 > 70\n",
      "1978 > 74\n",
      "1987 > 74\n",
      "1962 > 76\n",
      "844 > 28\n",
      "1994 > 207\n",
      "1896 > 222\n",
      "1802 > 216\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks[:20]:\n",
    "    print(len(chunk.page_content),\">\",len(chunk.page_content.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/ed/83/8aefc4d07624a868e046cc23ede8a59bebda57f09f72aee2150ef0855a82/faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.11/site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/pnkncv157yg1dmc6ncq9j2k80000gn/T/ipykernel_46293/3688831815.py:4: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding_model = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "\n",
    "faiss_index = FAISS.from_documents(documents=chunks,embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How do I detect objects in TensorFlow?'\n",
    "\n",
    "results = faiss_index.similarity_search(query, k=3)\n",
    "\n",
    "for res in results:\n",
    "    print(res.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQAWithSourcesChain(verbose=False, combine_documents_chain=MapReduceDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x107dc2610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1380051d0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), reduce_documents_chain=ReduceDocumentsChain(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'summaries'], input_types={}, partial_variables={}, template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x107dc2610>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1380051d0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content', 'source'], input_types={}, partial_variables={}, template='Content: {page_content}\\nSource: {source}'), document_variable_name='summaries')), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x355aa6150>, search_kwargs={}))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=faiss_index.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I detect objects in TensorFlow?',\n",
       " 'answer': 'To detect objects in TensorFlow, you can use the TensorFlow Hub Object Detection Colab, which provides pre-trained object detection models. You can select a model architecture and load pre-trained model weights. The TensorFlow Object Detection API can be used to visualize the results, including drawing boxes and labels on the image.\\n\\n',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I detect objects in TensorFlow?\"\n",
    "result = chain({\"question\": query})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
